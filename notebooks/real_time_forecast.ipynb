{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "data = torch.load(\"D:/GitHub/solar-forecasting/data/data_pipeline.pt\")\n",
    "X_tensor = data['X_tensor']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, bidirectional=True, dropout_p=0.3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            dropout=dropout_p, bidirectional=bidirectional,\n",
    "                            batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        direction_factor = 2 if bidirectional else 1\n",
    "        self.fc = nn.Linear(hidden_size * direction_factor, 1)  # Regression output\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        last_time_step_out = out[:, -1, :]\n",
    "        dropped = self.dropout(last_time_step_out)  # MC Dropout always applied\n",
    "        out = self.fc(dropped)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_mc_dropout(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Dropout):\n",
    "            m.train()  # Force dropout ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_predict(model, x_batch, n_passes=50):\n",
    "    model.eval()\n",
    "    enable_mc_dropout(model)\n",
    "\n",
    "    preds = []\n",
    "    for _ in range(n_passes):\n",
    "        with torch.no_grad():\n",
    "            preds.append(model(x_batch).cpu().numpy())\n",
    "\n",
    "    preds = np.stack(preds, axis=0)  # shape: (n_passes, batch_size)\n",
    "    mean = preds.mean(axis=0)        # shape: (batch_size,)\n",
    "    std = preds.std(axis=0)          # shape: (batch_size,)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Custom Dataset class for real-time evaluation (no labels or sample weights)\n",
    "class SequenceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "# Create the Dataset with just the input data (X) for real-time evaluation\n",
    "real_time_dataset = SequenceDataset(X_tensor)\n",
    "\n",
    "# Create the DataLoader for real-time evaluation\n",
    "real_time_loader = DataLoader(real_time_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Example: Using the DataLoader for real-time evaluation\n",
    "for batch in real_time_loader:\n",
    "    # Here you can use your model for prediction\n",
    "    # For example:\n",
    "    # predictions = model(batch)\n",
    "    print(batch.shape)  # Check the batch shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 21  # <-- replace with your real input size\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = LSTMModel(input_size=input_size)\n",
    "model.load_state_dict(torch.load(\"D:/GitHub/solar-forecasting/models/best_model_v2.pt\", map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = []\n",
    "all_stds = []\n",
    "\n",
    "model.eval()\n",
    "enable_mc_dropout(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in real_time_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        batch_mean, batch_std = mc_predict(model, X_batch, n_passes=50)\n",
    "        all_means.extend(batch_mean)\n",
    "        all_stds.extend(batch_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_means = np.array(all_means)\n",
    "all_stds = np.array(all_stds)\n",
    "mean_linear = all_means\n",
    "std_linear = ((all_means + all_stds)) - mean_linear  # approximate upper range\n",
    "\n",
    "for i in range(len(mean_linear)):\n",
    "    print(f\"Sample {i}: Flare = {mean_linear[i]:.2f}, Â± {std_linear[i]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
