{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import drms\n",
    "from drms import DrmsQueryError\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime as dt_obj\n",
    "import urllib\n",
    "from astropy.io import fits\n",
    "from sunpy.visualization.colormaps import color_tables as ct\n",
    "from matplotlib.dates import *\n",
    "from sunpy.time import TimeRange\n",
    "from sunpy.net import Fido\n",
    "from sunpy.net import attrs as a\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import csv\n",
    "from os.path import exists\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7704e",
   "metadata": {},
   "source": [
    "Download SHARP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333da406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initisalise drms client and display available data series\n",
    "c = drms.Client()\n",
    "c.series(r'hmi\\.sharp_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ecb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a series\n",
    "si = c.info('hmi.sharp_720s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f506b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise SHARP metadata features.\n",
    "fields = [\n",
    "    \"T_REC\", \n",
    "    \"HARPNUM\", \n",
    "    \"NOAA_NUM\", \n",
    "    \"NOAA_ARS\", \n",
    "    \"NOAA_AR\", \n",
    "    \"QUALITY\", \n",
    "    \"TOTUSJH\", \n",
    "    \"TOTUSJZ\", \n",
    "    \"SAVNCPP\", \n",
    "    \"USFLUX\", \n",
    "    \"ABSNJZH\", \n",
    "    \"TOTPOT\",\n",
    "    \"SIZE_ACR\", \n",
    "    \"NACR\", \n",
    "    \"MEANPOT\", \n",
    "    \"SIZE\", \n",
    "    \"MEANJZH\", \n",
    "    \"SHRGT45\", \n",
    "    \"MEANSHR\",\n",
    "    \"MEANJZD\", \n",
    "    \"MEANALP\", \n",
    "    \"MEANGBT\", \n",
    "    \"MEANGBL\", \n",
    "    \"MEANGAM\", \n",
    "    \"MEANGBZ\", \n",
    "    \"MEANGBH\", \n",
    "    \"NPIX\"\n",
    "]\n",
    "\n",
    "query_string = \",\".join(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a7b0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHARP metatdata overview\n",
    "sharp_subset = si.keywords.loc[si.keywords.index.intersection(fields)]\n",
    "sharp_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287f4f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define log and error files for download\n",
    "\n",
    "log_file = \"query_log.csv\"\n",
    "error_file = \"query_error.csv\"\n",
    "\n",
    "\n",
    "def log_success(log_file, t1_str, t2_str, n_rows):\n",
    "    write_header = not exists(log_file)\n",
    "    with open(log_file, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if write_header:\n",
    "            writer.writerow(['start_time', 'end_time', 'rows_written'])\n",
    "        writer.writerow([t1_str, t2_str, n_rows])\n",
    "\n",
    "def log_error(error_file, t1_str, t2_str, error):\n",
    "    write_header = not exists(error_file)\n",
    "    with open(error_file, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        if write_header:\n",
    "            writer.writerow(['start_time', 'end_time', 'error_message'])\n",
    "        writer.writerow([t1_str, t2_str, str(error)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9afa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download data to csv incrementally by day.\n",
    "\n",
    "start = datetime(2010, 5, 1)\n",
    "end = datetime(2025, 8, 21)\n",
    "\n",
    "first_write = True\n",
    "t_1 = end - timedelta(days=1)\n",
    "t_2 = end\n",
    "i = 1\n",
    "while t_1 >= start:\n",
    "    print(f\"Downloading day {i} of 5501\")\n",
    "    t_1_str = t_1.strftime(\"%Y.%m.%d_%H:%M:%S_TAI\") \n",
    "    t_2_str = t_2.strftime(\"%Y.%m.%d_%H:%M:%S_TAI\") \n",
    "    try:\n",
    "        extract = c.query(f'hmi.sharp_720s[1-13278][{t_1_str}-{t_2_str}]', key=query_string)\n",
    "\n",
    "        if not extract.empty:\n",
    "            extract.to_csv(\"sharp_metadata_dump_daily.csv\", mode='a', index=False, header=first_write)\n",
    "            first_write = False\n",
    "            print(f\"Wrote {len(extract)} rows for {t_1_str} - {t_2_str}\")\n",
    "            log_success(log_file, t_1, t_2, len(extract))\n",
    "        else:\n",
    "            print(f\"No records available for {t_1_str} - {t_2_str}\")\n",
    "            log_success(log_file, t_1, t_2, 0)\n",
    "\n",
    "    \n",
    "    except (DrmsQueryError, TimeoutError) as e:\n",
    "        print(f\"JSOC query failed for {t_1_str}-{t_2_str}: {e}\")\n",
    "        log_error(error_file, t_1, t_2, e)\n",
    "\n",
    "    t_1 = t_1 - timedelta(days=1)\n",
    "    t_2 = t_2 - timedelta(days=1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92de3c6",
   "metadata": {},
   "source": [
    "Download GOES flare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define download functions (Sun et al. 2022)\n",
    "\n",
    "def download_goes_per_year(t_start, t_end):\n",
    "    print(\"query started\")\n",
    "    results = Fido.search(\n",
    "        a.Time(t_start, t_end),\n",
    "        a.hek.EventType(\"FL\"),\n",
    "        # a.hek.FL.GOESCls > \"M1.0\",\n",
    "        a.hek.OBS.Observatory == \"GOES\"\n",
    "    )\n",
    "    print(\"query complete\")\n",
    "    if not results.all_colnames: # no columns / no results\n",
    "        return None\n",
    "    \n",
    "    event_table = results['hek'][\"event_starttime\", \"event_peaktime\", \"event_endtime\", \"fl_goescls\", \"ar_noaanum\"]\n",
    "    event_df = event_table.to_pandas().rename(columns={\n",
    "        'event_starttime': 'start_time',\n",
    "        'event_peaktime': 'peak_time',\n",
    "        'event_endtime': 'end_time',\n",
    "        'fl_goescls': 'goes_class',\n",
    "        #'hgc_coord': 'goes_location',\n",
    "        'ar_noaanum': 'noaa_active_region',\n",
    "    })\n",
    "    event_df = event_df[event_df['noaa_active_region'] != 0]\n",
    "    if len(event_df) == 0:\n",
    "        return None\n",
    "\n",
    "    return event_df\n",
    "\n",
    "\n",
    "def download_goes(t_start, t_end, first_write):\n",
    "\n",
    "    goes = download_goes_per_year(t_start, t_end)\n",
    "\n",
    "    if goes is not None and not goes.empty:\n",
    "        goes = goes[goes['goes_class'] != '']\n",
    "        goes.to_csv(\"goes_dump.csv\", mode='a', index=False, header=first_write)\n",
    "        first_write = False\n",
    "        print(f\"Wrote {len(goes)} rows for {t_start} - {t_end}\")\n",
    "        log_success(log_file, t_start, t_end, len(goes))\n",
    "    else:\n",
    "        print(f\"No records available for {t_start} - {t_end}\")\n",
    "        log_success(log_file, t_start, t_end, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313c712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download GOES data \n",
    "\n",
    "batch_start = datetime(2010, 5, 1)\n",
    "batch_end = datetime(2025, 5, 22)\n",
    "\n",
    "first_write = True\n",
    "t_start = batch_start\n",
    "t_end = t_start + relativedelta(months=1)\n",
    "while t_start < batch_end:\n",
    "    print(f\"Downoading {t_start} - {t_end}\")\n",
    "    download_goes(t_start, t_end, first_write)\n",
    "    t_start = t_start + relativedelta(months=1)\n",
    "    t_end = t_end + relativedelta(months=1)\n",
    "    first_write = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
