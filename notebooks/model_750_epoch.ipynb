{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_0QdC-JZLsiw"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in data\n",
        "data = torch.load('/content/preprocessed_data.pt')\n",
        "X_train = data['X_train']\n",
        "y_train = data['y_train']\n",
        "X_val = data['X_val']\n",
        "y_val = data['y_val']\n",
        "X_test = data['X_test']\n",
        "y_test = data['y_test']\n",
        "sample_weights = data['sample_weights']"
      ],
      "metadata": {
        "id": "kP8_k9nqL3Bo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LSTM, adapted from COMP534\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size=64, num_layers=2, bidirectional=True, dropout_p=0.3):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, 1)  # regression output\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.lstm(x)\n",
        "        last_time_step_out = out[:, -1, :]\n",
        "        out = self.fc(last_time_step_out)\n",
        "        return out.squeeze()\n"
      ],
      "metadata": {
        "id": "DfAiW_Q_L4LQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define weighted MSE loss function to address  data imbalance.\n",
        "def weighted_mse_loss(predictions, targets, weights):\n",
        "    return torch.mean(weights * (predictions - targets) ** 2)"
      ],
      "metadata": {
        "id": "fyrn5zoOL4b4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialse dataloaders using the train, validate and test datasets respectively.\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SequenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "class WeightedSequenceDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, y, weights=None):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.weights = weights if weights is not None else torch.ones(len(X))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx], self.weights[idx]\n",
        "\n",
        "# Use the weighted dataset for training\n",
        "train_dataset = WeightedSequenceDataset(X_train, y_train, sample_weights)\n",
        "\n",
        "# Dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "whVkOK5xL4pa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = SequenceDataset(X_test, y_test)\n",
        "val_dataset = SequenceDataset(X_val, y_val)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32)\n"
      ],
      "metadata": {
        "id": "ivpcLWgeL403"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise model and initial parameters\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_size = X_train.shape[2]  # number of SHARP features\n",
        "model = LSTMModel(input_size=input_size).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "DKA79IrwL49q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model, printing loss and validation loss per epoch.\n",
        "\n",
        "num_epochs = 750\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "patience = 1500\n",
        "counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for X_batch, y_batch, w_batch in train_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        w_batch = w_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = weighted_mse_loss(outputs, y_batch, w_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation (no weights)\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in val_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            outputs = model(X_batch)\n",
        "            loss = nn.functional.mse_loss(outputs, y_batch)\n",
        "            val_loss += loss.item() * X_batch.size(0)\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f} - Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        counter = 0  # Reset counter on improvement\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f'Validation loss increased ({val_loss:.4f}), patience {counter}/{patience}')\n",
        "        if counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xHwh5nAL5FC",
        "outputId": "5e5e711c-97c0-4d20-a6fd-22e6f69e751d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750 - Train Loss: 0.0645 - Val Loss: 7.2968\n",
            "Epoch 2/750 - Train Loss: 0.0490 - Val Loss: 6.3341\n",
            "Epoch 3/750 - Train Loss: 0.0419 - Val Loss: 4.5517\n",
            "Epoch 4/750 - Train Loss: 0.0381 - Val Loss: 4.7158\n",
            "Validation loss increased (4.7158), patience 1/1500\n",
            "Epoch 5/750 - Train Loss: 0.0373 - Val Loss: 3.8547\n",
            "Epoch 6/750 - Train Loss: 0.0350 - Val Loss: 5.3328\n",
            "Validation loss increased (5.3328), patience 1/1500\n",
            "Epoch 7/750 - Train Loss: 0.0344 - Val Loss: 4.6171\n",
            "Validation loss increased (4.6171), patience 2/1500\n",
            "Epoch 8/750 - Train Loss: 0.0340 - Val Loss: 3.9664\n",
            "Validation loss increased (3.9664), patience 3/1500\n",
            "Epoch 9/750 - Train Loss: 0.0334 - Val Loss: 5.2988\n",
            "Validation loss increased (5.2988), patience 4/1500\n",
            "Epoch 10/750 - Train Loss: 0.0331 - Val Loss: 3.5224\n",
            "Epoch 11/750 - Train Loss: 0.0331 - Val Loss: 4.5377\n",
            "Validation loss increased (4.5377), patience 1/1500\n",
            "Epoch 12/750 - Train Loss: 0.0331 - Val Loss: 4.8381\n",
            "Validation loss increased (4.8381), patience 2/1500\n",
            "Epoch 13/750 - Train Loss: 0.0325 - Val Loss: 3.8380\n",
            "Validation loss increased (3.8380), patience 3/1500\n",
            "Epoch 14/750 - Train Loss: 0.0329 - Val Loss: 6.1103\n",
            "Validation loss increased (6.1103), patience 4/1500\n",
            "Epoch 15/750 - Train Loss: 0.0324 - Val Loss: 5.3602\n",
            "Validation loss increased (5.3602), patience 5/1500\n",
            "Epoch 16/750 - Train Loss: 0.0328 - Val Loss: 3.9851\n",
            "Validation loss increased (3.9851), patience 6/1500\n",
            "Epoch 17/750 - Train Loss: 0.0318 - Val Loss: 4.0178\n",
            "Validation loss increased (4.0178), patience 7/1500\n",
            "Epoch 18/750 - Train Loss: 0.0324 - Val Loss: 3.7003\n",
            "Validation loss increased (3.7003), patience 8/1500\n",
            "Epoch 19/750 - Train Loss: 0.0316 - Val Loss: 4.1123\n",
            "Validation loss increased (4.1123), patience 9/1500\n",
            "Epoch 20/750 - Train Loss: 0.0321 - Val Loss: 3.6939\n",
            "Validation loss increased (3.6939), patience 10/1500\n",
            "Epoch 21/750 - Train Loss: 0.0321 - Val Loss: 4.3187\n",
            "Validation loss increased (4.3187), patience 11/1500\n",
            "Epoch 22/750 - Train Loss: 0.0318 - Val Loss: 5.2556\n",
            "Validation loss increased (5.2556), patience 12/1500\n",
            "Epoch 23/750 - Train Loss: 0.0315 - Val Loss: 4.9930\n",
            "Validation loss increased (4.9930), patience 13/1500\n",
            "Epoch 24/750 - Train Loss: 0.0318 - Val Loss: 3.4144\n",
            "Epoch 25/750 - Train Loss: 0.0318 - Val Loss: 4.6594\n",
            "Validation loss increased (4.6594), patience 1/1500\n",
            "Epoch 26/750 - Train Loss: 0.0315 - Val Loss: 6.0030\n",
            "Validation loss increased (6.0030), patience 2/1500\n",
            "Epoch 27/750 - Train Loss: 0.0316 - Val Loss: 3.6448\n",
            "Validation loss increased (3.6448), patience 3/1500\n",
            "Epoch 28/750 - Train Loss: 0.0313 - Val Loss: 3.6904\n",
            "Validation loss increased (3.6904), patience 4/1500\n",
            "Epoch 29/750 - Train Loss: 0.0314 - Val Loss: 4.4147\n",
            "Validation loss increased (4.4147), patience 5/1500\n",
            "Epoch 30/750 - Train Loss: 0.0314 - Val Loss: 3.9219\n",
            "Validation loss increased (3.9219), patience 6/1500\n",
            "Epoch 31/750 - Train Loss: 0.0310 - Val Loss: 3.7101\n",
            "Validation loss increased (3.7101), patience 7/1500\n",
            "Epoch 32/750 - Train Loss: 0.0312 - Val Loss: 4.7186\n",
            "Validation loss increased (4.7186), patience 8/1500\n",
            "Epoch 33/750 - Train Loss: 0.0311 - Val Loss: 3.5705\n",
            "Validation loss increased (3.5705), patience 9/1500\n",
            "Epoch 34/750 - Train Loss: 0.0312 - Val Loss: 4.6684\n",
            "Validation loss increased (4.6684), patience 10/1500\n",
            "Epoch 35/750 - Train Loss: 0.0313 - Val Loss: 3.7901\n",
            "Validation loss increased (3.7901), patience 11/1500\n",
            "Epoch 36/750 - Train Loss: 0.0309 - Val Loss: 4.7925\n",
            "Validation loss increased (4.7925), patience 12/1500\n",
            "Epoch 37/750 - Train Loss: 0.0311 - Val Loss: 4.2442\n",
            "Validation loss increased (4.2442), patience 13/1500\n",
            "Epoch 38/750 - Train Loss: 0.0308 - Val Loss: 3.5652\n",
            "Validation loss increased (3.5652), patience 14/1500\n",
            "Epoch 39/750 - Train Loss: 0.0312 - Val Loss: 4.2014\n",
            "Validation loss increased (4.2014), patience 15/1500\n",
            "Epoch 40/750 - Train Loss: 0.0312 - Val Loss: 4.1666\n",
            "Validation loss increased (4.1666), patience 16/1500\n",
            "Epoch 41/750 - Train Loss: 0.0312 - Val Loss: 3.6221\n",
            "Validation loss increased (3.6221), patience 17/1500\n",
            "Epoch 42/750 - Train Loss: 0.0308 - Val Loss: 4.8829\n",
            "Validation loss increased (4.8829), patience 18/1500\n",
            "Epoch 43/750 - Train Loss: 0.0306 - Val Loss: 3.9725\n",
            "Validation loss increased (3.9725), patience 19/1500\n",
            "Epoch 44/750 - Train Loss: 0.0309 - Val Loss: 4.1579\n",
            "Validation loss increased (4.1579), patience 20/1500\n",
            "Epoch 45/750 - Train Loss: 0.0306 - Val Loss: 3.5718\n",
            "Validation loss increased (3.5718), patience 21/1500\n",
            "Epoch 46/750 - Train Loss: 0.0311 - Val Loss: 4.1295\n",
            "Validation loss increased (4.1295), patience 22/1500\n",
            "Epoch 47/750 - Train Loss: 0.0307 - Val Loss: 4.8852\n",
            "Validation loss increased (4.8852), patience 23/1500\n",
            "Epoch 48/750 - Train Loss: 0.0302 - Val Loss: 6.2261\n",
            "Validation loss increased (6.2261), patience 24/1500\n",
            "Epoch 49/750 - Train Loss: 0.0307 - Val Loss: 3.5589\n",
            "Validation loss increased (3.5589), patience 25/1500\n",
            "Epoch 50/750 - Train Loss: 0.0303 - Val Loss: 4.2340\n",
            "Validation loss increased (4.2340), patience 26/1500\n",
            "Epoch 51/750 - Train Loss: 0.0304 - Val Loss: 4.2457\n",
            "Validation loss increased (4.2457), patience 27/1500\n",
            "Epoch 52/750 - Train Loss: 0.0305 - Val Loss: 4.2777\n",
            "Validation loss increased (4.2777), patience 28/1500\n",
            "Epoch 53/750 - Train Loss: 0.0298 - Val Loss: 3.9863\n",
            "Validation loss increased (3.9863), patience 29/1500\n",
            "Epoch 54/750 - Train Loss: 0.0305 - Val Loss: 5.6142\n",
            "Validation loss increased (5.6142), patience 30/1500\n",
            "Epoch 55/750 - Train Loss: 0.0301 - Val Loss: 4.9242\n",
            "Validation loss increased (4.9242), patience 31/1500\n",
            "Epoch 56/750 - Train Loss: 0.0303 - Val Loss: 3.7688\n",
            "Validation loss increased (3.7688), patience 32/1500\n",
            "Epoch 57/750 - Train Loss: 0.0300 - Val Loss: 5.7746\n",
            "Validation loss increased (5.7746), patience 33/1500\n",
            "Epoch 58/750 - Train Loss: 0.0303 - Val Loss: 4.3984\n",
            "Validation loss increased (4.3984), patience 34/1500\n",
            "Epoch 59/750 - Train Loss: 0.0298 - Val Loss: 4.8413\n",
            "Validation loss increased (4.8413), patience 35/1500\n",
            "Epoch 60/750 - Train Loss: 0.0297 - Val Loss: 3.2464\n",
            "Epoch 61/750 - Train Loss: 0.0292 - Val Loss: 3.7833\n",
            "Validation loss increased (3.7833), patience 1/1500\n",
            "Epoch 62/750 - Train Loss: 0.0300 - Val Loss: 4.1933\n",
            "Validation loss increased (4.1933), patience 2/1500\n",
            "Epoch 63/750 - Train Loss: 0.0295 - Val Loss: 4.6764\n",
            "Validation loss increased (4.6764), patience 3/1500\n",
            "Epoch 64/750 - Train Loss: 0.0296 - Val Loss: 5.0304\n",
            "Validation loss increased (5.0304), patience 4/1500\n",
            "Epoch 65/750 - Train Loss: 0.0300 - Val Loss: 3.3656\n",
            "Validation loss increased (3.3656), patience 5/1500\n",
            "Epoch 66/750 - Train Loss: 0.0294 - Val Loss: 3.4163\n",
            "Validation loss increased (3.4163), patience 6/1500\n",
            "Epoch 67/750 - Train Loss: 0.0294 - Val Loss: 4.4466\n",
            "Validation loss increased (4.4466), patience 7/1500\n",
            "Epoch 68/750 - Train Loss: 0.0294 - Val Loss: 3.3588\n",
            "Validation loss increased (3.3588), patience 8/1500\n",
            "Epoch 69/750 - Train Loss: 0.0294 - Val Loss: 4.5293\n",
            "Validation loss increased (4.5293), patience 9/1500\n",
            "Epoch 70/750 - Train Loss: 0.0291 - Val Loss: 4.7475\n",
            "Validation loss increased (4.7475), patience 10/1500\n",
            "Epoch 71/750 - Train Loss: 0.0289 - Val Loss: 3.5114\n",
            "Validation loss increased (3.5114), patience 11/1500\n",
            "Epoch 72/750 - Train Loss: 0.0293 - Val Loss: 7.5759\n",
            "Validation loss increased (7.5759), patience 12/1500\n",
            "Epoch 73/750 - Train Loss: 0.0290 - Val Loss: 3.8924\n",
            "Validation loss increased (3.8924), patience 13/1500\n",
            "Epoch 74/750 - Train Loss: 0.0287 - Val Loss: 3.2024\n",
            "Epoch 75/750 - Train Loss: 0.0284 - Val Loss: 3.9931\n",
            "Validation loss increased (3.9931), patience 1/1500\n",
            "Epoch 76/750 - Train Loss: 0.0294 - Val Loss: 3.6737\n",
            "Validation loss increased (3.6737), patience 2/1500\n",
            "Epoch 77/750 - Train Loss: 0.0290 - Val Loss: 2.8288\n",
            "Epoch 78/750 - Train Loss: 0.0286 - Val Loss: 3.0570\n",
            "Validation loss increased (3.0570), patience 1/1500\n",
            "Epoch 79/750 - Train Loss: 0.0296 - Val Loss: 4.5213\n",
            "Validation loss increased (4.5213), patience 2/1500\n",
            "Epoch 80/750 - Train Loss: 0.0291 - Val Loss: 4.0903\n",
            "Validation loss increased (4.0903), patience 3/1500\n",
            "Epoch 81/750 - Train Loss: 0.0288 - Val Loss: 3.6414\n",
            "Validation loss increased (3.6414), patience 4/1500\n",
            "Epoch 82/750 - Train Loss: 0.0283 - Val Loss: 3.0118\n",
            "Validation loss increased (3.0118), patience 5/1500\n",
            "Epoch 83/750 - Train Loss: 0.0292 - Val Loss: 4.3938\n",
            "Validation loss increased (4.3938), patience 6/1500\n",
            "Epoch 84/750 - Train Loss: 0.0289 - Val Loss: 3.5952\n",
            "Validation loss increased (3.5952), patience 7/1500\n",
            "Epoch 85/750 - Train Loss: 0.0286 - Val Loss: 3.9007\n",
            "Validation loss increased (3.9007), patience 8/1500\n",
            "Epoch 86/750 - Train Loss: 0.0280 - Val Loss: 3.7075\n",
            "Validation loss increased (3.7075), patience 9/1500\n",
            "Epoch 87/750 - Train Loss: 0.0282 - Val Loss: 3.3676\n",
            "Validation loss increased (3.3676), patience 10/1500\n",
            "Epoch 88/750 - Train Loss: 0.0281 - Val Loss: 4.2867\n",
            "Validation loss increased (4.2867), patience 11/1500\n",
            "Epoch 89/750 - Train Loss: 0.0280 - Val Loss: 3.6855\n",
            "Validation loss increased (3.6855), patience 12/1500\n",
            "Epoch 90/750 - Train Loss: 0.0282 - Val Loss: 4.1272\n",
            "Validation loss increased (4.1272), patience 13/1500\n",
            "Epoch 91/750 - Train Loss: 0.0276 - Val Loss: 5.2793\n",
            "Validation loss increased (5.2793), patience 14/1500\n",
            "Epoch 92/750 - Train Loss: 0.0285 - Val Loss: 4.1615\n",
            "Validation loss increased (4.1615), patience 15/1500\n",
            "Epoch 93/750 - Train Loss: 0.0276 - Val Loss: 4.9883\n",
            "Validation loss increased (4.9883), patience 16/1500\n",
            "Epoch 94/750 - Train Loss: 0.0283 - Val Loss: 4.0557\n",
            "Validation loss increased (4.0557), patience 17/1500\n",
            "Epoch 95/750 - Train Loss: 0.0276 - Val Loss: 3.5193\n",
            "Validation loss increased (3.5193), patience 18/1500\n",
            "Epoch 96/750 - Train Loss: 0.0281 - Val Loss: 3.7523\n",
            "Validation loss increased (3.7523), patience 19/1500\n",
            "Epoch 97/750 - Train Loss: 0.0283 - Val Loss: 3.8470\n",
            "Validation loss increased (3.8470), patience 20/1500\n",
            "Epoch 98/750 - Train Loss: 0.0274 - Val Loss: 3.2939\n",
            "Validation loss increased (3.2939), patience 21/1500\n",
            "Epoch 99/750 - Train Loss: 0.0271 - Val Loss: 3.5941\n",
            "Validation loss increased (3.5941), patience 22/1500\n",
            "Epoch 100/750 - Train Loss: 0.0282 - Val Loss: 3.7031\n",
            "Validation loss increased (3.7031), patience 23/1500\n",
            "Epoch 101/750 - Train Loss: 0.0294 - Val Loss: 3.2838\n",
            "Validation loss increased (3.2838), patience 24/1500\n",
            "Epoch 102/750 - Train Loss: 0.0277 - Val Loss: 3.3890\n",
            "Validation loss increased (3.3890), patience 25/1500\n",
            "Epoch 103/750 - Train Loss: 0.0272 - Val Loss: 3.6610\n",
            "Validation loss increased (3.6610), patience 26/1500\n",
            "Epoch 104/750 - Train Loss: 0.0273 - Val Loss: 4.4902\n",
            "Validation loss increased (4.4902), patience 27/1500\n",
            "Epoch 105/750 - Train Loss: 0.0276 - Val Loss: 4.3879\n",
            "Validation loss increased (4.3879), patience 28/1500\n",
            "Epoch 106/750 - Train Loss: 0.0280 - Val Loss: 3.5790\n",
            "Validation loss increased (3.5790), patience 29/1500\n",
            "Epoch 107/750 - Train Loss: 0.0275 - Val Loss: 3.4483\n",
            "Validation loss increased (3.4483), patience 30/1500\n",
            "Epoch 108/750 - Train Loss: 0.0283 - Val Loss: 4.3208\n",
            "Validation loss increased (4.3208), patience 31/1500\n",
            "Epoch 109/750 - Train Loss: 0.0281 - Val Loss: 4.1977\n",
            "Validation loss increased (4.1977), patience 32/1500\n",
            "Epoch 110/750 - Train Loss: 0.0271 - Val Loss: 3.2346\n",
            "Validation loss increased (3.2346), patience 33/1500\n",
            "Epoch 111/750 - Train Loss: 0.0270 - Val Loss: 3.5925\n",
            "Validation loss increased (3.5925), patience 34/1500\n",
            "Epoch 112/750 - Train Loss: 0.0273 - Val Loss: 4.5816\n",
            "Validation loss increased (4.5816), patience 35/1500\n",
            "Epoch 113/750 - Train Loss: 0.0271 - Val Loss: 3.1825\n",
            "Validation loss increased (3.1825), patience 36/1500\n",
            "Epoch 114/750 - Train Loss: 0.0279 - Val Loss: 5.3917\n",
            "Validation loss increased (5.3917), patience 37/1500\n",
            "Epoch 115/750 - Train Loss: 0.0293 - Val Loss: 3.1305\n",
            "Validation loss increased (3.1305), patience 38/1500\n",
            "Epoch 116/750 - Train Loss: 0.0273 - Val Loss: 3.7984\n",
            "Validation loss increased (3.7984), patience 39/1500\n",
            "Epoch 117/750 - Train Loss: 0.0271 - Val Loss: 3.0711\n",
            "Validation loss increased (3.0711), patience 40/1500\n",
            "Epoch 118/750 - Train Loss: 0.0269 - Val Loss: 3.1473\n",
            "Validation loss increased (3.1473), patience 41/1500\n",
            "Epoch 119/750 - Train Loss: 0.0274 - Val Loss: 3.4594\n",
            "Validation loss increased (3.4594), patience 42/1500\n",
            "Epoch 120/750 - Train Loss: 0.0268 - Val Loss: 4.1125\n",
            "Validation loss increased (4.1125), patience 43/1500\n",
            "Epoch 121/750 - Train Loss: 0.0268 - Val Loss: 3.4137\n",
            "Validation loss increased (3.4137), patience 44/1500\n",
            "Epoch 122/750 - Train Loss: 0.0271 - Val Loss: 5.1323\n",
            "Validation loss increased (5.1323), patience 45/1500\n",
            "Epoch 123/750 - Train Loss: 0.0270 - Val Loss: 4.0686\n",
            "Validation loss increased (4.0686), patience 46/1500\n",
            "Epoch 124/750 - Train Loss: 0.0264 - Val Loss: 3.5544\n",
            "Validation loss increased (3.5544), patience 47/1500\n",
            "Epoch 125/750 - Train Loss: 0.0270 - Val Loss: 3.2925\n",
            "Validation loss increased (3.2925), patience 48/1500\n",
            "Epoch 126/750 - Train Loss: 0.0267 - Val Loss: 3.6836\n",
            "Validation loss increased (3.6836), patience 49/1500\n",
            "Epoch 127/750 - Train Loss: 0.0266 - Val Loss: 4.3139\n",
            "Validation loss increased (4.3139), patience 50/1500\n",
            "Epoch 128/750 - Train Loss: 0.0269 - Val Loss: 3.4760\n",
            "Validation loss increased (3.4760), patience 51/1500\n",
            "Epoch 129/750 - Train Loss: 0.0267 - Val Loss: 5.5917\n",
            "Validation loss increased (5.5917), patience 52/1500\n",
            "Epoch 130/750 - Train Loss: 0.0268 - Val Loss: 3.6365\n",
            "Validation loss increased (3.6365), patience 53/1500\n",
            "Epoch 131/750 - Train Loss: 0.0272 - Val Loss: 3.3765\n",
            "Validation loss increased (3.3765), patience 54/1500\n",
            "Epoch 132/750 - Train Loss: 0.0266 - Val Loss: 3.6843\n",
            "Validation loss increased (3.6843), patience 55/1500\n",
            "Epoch 133/750 - Train Loss: 0.0270 - Val Loss: 3.4231\n",
            "Validation loss increased (3.4231), patience 56/1500\n",
            "Epoch 134/750 - Train Loss: 0.0267 - Val Loss: 4.2501\n",
            "Validation loss increased (4.2501), patience 57/1500\n",
            "Epoch 135/750 - Train Loss: 0.0267 - Val Loss: 3.8952\n",
            "Validation loss increased (3.8952), patience 58/1500\n",
            "Epoch 136/750 - Train Loss: 0.0268 - Val Loss: 4.3564\n",
            "Validation loss increased (4.3564), patience 59/1500\n",
            "Epoch 137/750 - Train Loss: 0.0266 - Val Loss: 3.4716\n",
            "Validation loss increased (3.4716), patience 60/1500\n",
            "Epoch 138/750 - Train Loss: 0.0265 - Val Loss: 4.1267\n",
            "Validation loss increased (4.1267), patience 61/1500\n",
            "Epoch 139/750 - Train Loss: 0.0265 - Val Loss: 3.4044\n",
            "Validation loss increased (3.4044), patience 62/1500\n",
            "Epoch 140/750 - Train Loss: 0.0267 - Val Loss: 3.7087\n",
            "Validation loss increased (3.7087), patience 63/1500\n",
            "Epoch 141/750 - Train Loss: 0.0269 - Val Loss: 4.6362\n",
            "Validation loss increased (4.6362), patience 64/1500\n",
            "Epoch 142/750 - Train Loss: 0.0261 - Val Loss: 3.4815\n",
            "Validation loss increased (3.4815), patience 65/1500\n",
            "Epoch 143/750 - Train Loss: 0.0264 - Val Loss: 4.1002\n",
            "Validation loss increased (4.1002), patience 66/1500\n",
            "Epoch 144/750 - Train Loss: 0.0269 - Val Loss: 4.6468\n",
            "Validation loss increased (4.6468), patience 67/1500\n",
            "Epoch 145/750 - Train Loss: 0.0263 - Val Loss: 3.3299\n",
            "Validation loss increased (3.3299), patience 68/1500\n",
            "Epoch 146/750 - Train Loss: 0.0267 - Val Loss: 3.7108\n",
            "Validation loss increased (3.7108), patience 69/1500\n",
            "Epoch 147/750 - Train Loss: 0.0266 - Val Loss: 4.1545\n",
            "Validation loss increased (4.1545), patience 70/1500\n",
            "Epoch 148/750 - Train Loss: 0.0259 - Val Loss: 3.1427\n",
            "Validation loss increased (3.1427), patience 71/1500\n",
            "Epoch 149/750 - Train Loss: 0.0265 - Val Loss: 3.0739\n",
            "Validation loss increased (3.0739), patience 72/1500\n",
            "Epoch 150/750 - Train Loss: 0.0269 - Val Loss: 3.2548\n",
            "Validation loss increased (3.2548), patience 73/1500\n",
            "Epoch 151/750 - Train Loss: 0.0261 - Val Loss: 3.6244\n",
            "Validation loss increased (3.6244), patience 74/1500\n",
            "Epoch 152/750 - Train Loss: 0.0277 - Val Loss: 3.8910\n",
            "Validation loss increased (3.8910), patience 75/1500\n",
            "Epoch 153/750 - Train Loss: 0.0263 - Val Loss: 5.5984\n",
            "Validation loss increased (5.5984), patience 76/1500\n",
            "Epoch 154/750 - Train Loss: 0.0271 - Val Loss: 3.9095\n",
            "Validation loss increased (3.9095), patience 77/1500\n",
            "Epoch 155/750 - Train Loss: 0.0282 - Val Loss: 3.6466\n",
            "Validation loss increased (3.6466), patience 78/1500\n",
            "Epoch 156/750 - Train Loss: 0.0277 - Val Loss: 3.6931\n",
            "Validation loss increased (3.6931), patience 79/1500\n",
            "Epoch 157/750 - Train Loss: 0.0272 - Val Loss: 3.2300\n",
            "Validation loss increased (3.2300), patience 80/1500\n",
            "Epoch 158/750 - Train Loss: 0.0265 - Val Loss: 3.5115\n",
            "Validation loss increased (3.5115), patience 81/1500\n",
            "Epoch 159/750 - Train Loss: 0.0261 - Val Loss: 3.0484\n",
            "Validation loss increased (3.0484), patience 82/1500\n",
            "Epoch 160/750 - Train Loss: 0.0262 - Val Loss: 3.1230\n",
            "Validation loss increased (3.1230), patience 83/1500\n",
            "Epoch 161/750 - Train Loss: 0.0262 - Val Loss: 4.1299\n",
            "Validation loss increased (4.1299), patience 84/1500\n",
            "Epoch 162/750 - Train Loss: 0.0259 - Val Loss: 3.5412\n",
            "Validation loss increased (3.5412), patience 85/1500\n",
            "Epoch 163/750 - Train Loss: 0.0266 - Val Loss: 4.0387\n",
            "Validation loss increased (4.0387), patience 86/1500\n",
            "Epoch 164/750 - Train Loss: 0.0276 - Val Loss: 3.6109\n",
            "Validation loss increased (3.6109), patience 87/1500\n",
            "Epoch 165/750 - Train Loss: 0.0260 - Val Loss: 4.2678\n",
            "Validation loss increased (4.2678), patience 88/1500\n",
            "Epoch 166/750 - Train Loss: 0.0263 - Val Loss: 3.0959\n",
            "Validation loss increased (3.0959), patience 89/1500\n",
            "Epoch 167/750 - Train Loss: 0.0260 - Val Loss: 2.9603\n",
            "Validation loss increased (2.9603), patience 90/1500\n",
            "Epoch 168/750 - Train Loss: 0.0259 - Val Loss: 3.3955\n",
            "Validation loss increased (3.3955), patience 91/1500\n",
            "Epoch 169/750 - Train Loss: 0.0260 - Val Loss: 3.6209\n",
            "Validation loss increased (3.6209), patience 92/1500\n",
            "Epoch 170/750 - Train Loss: 0.0262 - Val Loss: 4.1309\n",
            "Validation loss increased (4.1309), patience 93/1500\n",
            "Epoch 171/750 - Train Loss: 0.0265 - Val Loss: 3.4852\n",
            "Validation loss increased (3.4852), patience 94/1500\n",
            "Epoch 172/750 - Train Loss: 0.0276 - Val Loss: 3.9292\n",
            "Validation loss increased (3.9292), patience 95/1500\n",
            "Epoch 173/750 - Train Loss: 0.0264 - Val Loss: 4.0697\n",
            "Validation loss increased (4.0697), patience 96/1500\n",
            "Epoch 174/750 - Train Loss: 0.0258 - Val Loss: 3.8099\n",
            "Validation loss increased (3.8099), patience 97/1500\n",
            "Epoch 175/750 - Train Loss: 0.0256 - Val Loss: 3.4083\n",
            "Validation loss increased (3.4083), patience 98/1500\n",
            "Epoch 176/750 - Train Loss: 0.0258 - Val Loss: 3.6495\n",
            "Validation loss increased (3.6495), patience 99/1500\n",
            "Epoch 177/750 - Train Loss: 0.0262 - Val Loss: 3.5471\n",
            "Validation loss increased (3.5471), patience 100/1500\n",
            "Epoch 178/750 - Train Loss: 0.0260 - Val Loss: 3.1964\n",
            "Validation loss increased (3.1964), patience 101/1500\n",
            "Epoch 179/750 - Train Loss: 0.0254 - Val Loss: 3.6360\n",
            "Validation loss increased (3.6360), patience 102/1500\n",
            "Epoch 180/750 - Train Loss: 0.0256 - Val Loss: 3.1910\n",
            "Validation loss increased (3.1910), patience 103/1500\n",
            "Epoch 181/750 - Train Loss: 0.0259 - Val Loss: 4.0535\n",
            "Validation loss increased (4.0535), patience 104/1500\n",
            "Epoch 182/750 - Train Loss: 0.0262 - Val Loss: 3.9501\n",
            "Validation loss increased (3.9501), patience 105/1500\n",
            "Epoch 183/750 - Train Loss: 0.0255 - Val Loss: 3.3642\n",
            "Validation loss increased (3.3642), patience 106/1500\n",
            "Epoch 184/750 - Train Loss: 0.0253 - Val Loss: 4.3505\n",
            "Validation loss increased (4.3505), patience 107/1500\n",
            "Epoch 185/750 - Train Loss: 0.0274 - Val Loss: 4.5247\n",
            "Validation loss increased (4.5247), patience 108/1500\n",
            "Epoch 186/750 - Train Loss: 0.0256 - Val Loss: 3.4432\n",
            "Validation loss increased (3.4432), patience 109/1500\n",
            "Epoch 187/750 - Train Loss: 0.0262 - Val Loss: 3.5860\n",
            "Validation loss increased (3.5860), patience 110/1500\n",
            "Epoch 188/750 - Train Loss: 0.0269 - Val Loss: 4.2343\n",
            "Validation loss increased (4.2343), patience 111/1500\n",
            "Epoch 189/750 - Train Loss: 0.0261 - Val Loss: 3.3094\n",
            "Validation loss increased (3.3094), patience 112/1500\n",
            "Epoch 190/750 - Train Loss: 0.0258 - Val Loss: 3.5989\n",
            "Validation loss increased (3.5989), patience 113/1500\n",
            "Epoch 191/750 - Train Loss: 0.0267 - Val Loss: 4.3223\n",
            "Validation loss increased (4.3223), patience 114/1500\n",
            "Epoch 192/750 - Train Loss: 0.0257 - Val Loss: 3.2252\n",
            "Validation loss increased (3.2252), patience 115/1500\n",
            "Epoch 193/750 - Train Loss: 0.0258 - Val Loss: 3.1575\n",
            "Validation loss increased (3.1575), patience 116/1500\n",
            "Epoch 194/750 - Train Loss: 0.0262 - Val Loss: 3.5177\n",
            "Validation loss increased (3.5177), patience 117/1500\n",
            "Epoch 195/750 - Train Loss: 0.0261 - Val Loss: 3.1448\n",
            "Validation loss increased (3.1448), patience 118/1500\n",
            "Epoch 196/750 - Train Loss: 0.0259 - Val Loss: 3.4048\n",
            "Validation loss increased (3.4048), patience 119/1500\n",
            "Epoch 197/750 - Train Loss: 0.0266 - Val Loss: 3.2614\n",
            "Validation loss increased (3.2614), patience 120/1500\n",
            "Epoch 198/750 - Train Loss: 0.0256 - Val Loss: 2.7201\n",
            "Epoch 199/750 - Train Loss: 0.0260 - Val Loss: 3.9135\n",
            "Validation loss increased (3.9135), patience 1/1500\n",
            "Epoch 200/750 - Train Loss: 0.0255 - Val Loss: 2.9073\n",
            "Validation loss increased (2.9073), patience 2/1500\n",
            "Epoch 201/750 - Train Loss: 0.0260 - Val Loss: 5.1191\n",
            "Validation loss increased (5.1191), patience 3/1500\n",
            "Epoch 202/750 - Train Loss: 0.0265 - Val Loss: 4.3485\n",
            "Validation loss increased (4.3485), patience 4/1500\n",
            "Epoch 203/750 - Train Loss: 0.0253 - Val Loss: 3.4331\n",
            "Validation loss increased (3.4331), patience 5/1500\n",
            "Epoch 204/750 - Train Loss: 0.0253 - Val Loss: 3.0774\n",
            "Validation loss increased (3.0774), patience 6/1500\n",
            "Epoch 205/750 - Train Loss: 0.0257 - Val Loss: 3.3847\n",
            "Validation loss increased (3.3847), patience 7/1500\n",
            "Epoch 206/750 - Train Loss: 0.0271 - Val Loss: 3.1381\n",
            "Validation loss increased (3.1381), patience 8/1500\n",
            "Epoch 207/750 - Train Loss: 0.0258 - Val Loss: 3.2736\n",
            "Validation loss increased (3.2736), patience 9/1500\n",
            "Epoch 208/750 - Train Loss: 0.0251 - Val Loss: 4.7506\n",
            "Validation loss increased (4.7506), patience 10/1500\n",
            "Epoch 209/750 - Train Loss: 0.0301 - Val Loss: 3.7977\n",
            "Validation loss increased (3.7977), patience 11/1500\n",
            "Epoch 210/750 - Train Loss: 0.0282 - Val Loss: 3.6971\n",
            "Validation loss increased (3.6971), patience 12/1500\n",
            "Epoch 211/750 - Train Loss: 0.0278 - Val Loss: 3.8635\n",
            "Validation loss increased (3.8635), patience 13/1500\n",
            "Epoch 212/750 - Train Loss: 0.0269 - Val Loss: 3.8976\n",
            "Validation loss increased (3.8976), patience 14/1500\n",
            "Epoch 213/750 - Train Loss: 0.0258 - Val Loss: 3.9378\n",
            "Validation loss increased (3.9378), patience 15/1500\n",
            "Epoch 214/750 - Train Loss: 0.0256 - Val Loss: 5.2376\n",
            "Validation loss increased (5.2376), patience 16/1500\n",
            "Epoch 215/750 - Train Loss: 0.0257 - Val Loss: 3.8103\n",
            "Validation loss increased (3.8103), patience 17/1500\n",
            "Epoch 216/750 - Train Loss: 0.0257 - Val Loss: 3.6963\n",
            "Validation loss increased (3.6963), patience 18/1500\n",
            "Epoch 217/750 - Train Loss: 0.0257 - Val Loss: 3.7362\n",
            "Validation loss increased (3.7362), patience 19/1500\n",
            "Epoch 218/750 - Train Loss: 0.0252 - Val Loss: 3.9161\n",
            "Validation loss increased (3.9161), patience 20/1500\n",
            "Epoch 219/750 - Train Loss: 0.0256 - Val Loss: 3.3278\n",
            "Validation loss increased (3.3278), patience 21/1500\n",
            "Epoch 220/750 - Train Loss: 0.0269 - Val Loss: 3.4890\n",
            "Validation loss increased (3.4890), patience 22/1500\n",
            "Epoch 221/750 - Train Loss: 0.0255 - Val Loss: 3.3124\n",
            "Validation loss increased (3.3124), patience 23/1500\n",
            "Epoch 222/750 - Train Loss: 0.0253 - Val Loss: 3.7973\n",
            "Validation loss increased (3.7973), patience 24/1500\n",
            "Epoch 223/750 - Train Loss: 0.0257 - Val Loss: 4.0901\n",
            "Validation loss increased (4.0901), patience 25/1500\n",
            "Epoch 224/750 - Train Loss: 0.0250 - Val Loss: 3.3383\n",
            "Validation loss increased (3.3383), patience 26/1500\n",
            "Epoch 225/750 - Train Loss: 0.0247 - Val Loss: 3.5013\n",
            "Validation loss increased (3.5013), patience 27/1500\n",
            "Epoch 226/750 - Train Loss: 0.0262 - Val Loss: 3.2672\n",
            "Validation loss increased (3.2672), patience 28/1500\n",
            "Epoch 227/750 - Train Loss: 0.0252 - Val Loss: 2.7972\n",
            "Validation loss increased (2.7972), patience 29/1500\n",
            "Epoch 228/750 - Train Loss: 0.0256 - Val Loss: 2.9560\n",
            "Validation loss increased (2.9560), patience 30/1500\n",
            "Epoch 229/750 - Train Loss: 0.0253 - Val Loss: 3.5736\n",
            "Validation loss increased (3.5736), patience 31/1500\n",
            "Epoch 230/750 - Train Loss: 0.0254 - Val Loss: 4.5486\n",
            "Validation loss increased (4.5486), patience 32/1500\n",
            "Epoch 231/750 - Train Loss: 0.0251 - Val Loss: 3.3066\n",
            "Validation loss increased (3.3066), patience 33/1500\n",
            "Epoch 232/750 - Train Loss: 0.0274 - Val Loss: 4.6530\n",
            "Validation loss increased (4.6530), patience 34/1500\n",
            "Epoch 233/750 - Train Loss: 0.0284 - Val Loss: 3.0964\n",
            "Validation loss increased (3.0964), patience 35/1500\n",
            "Epoch 234/750 - Train Loss: 0.0263 - Val Loss: 3.0005\n",
            "Validation loss increased (3.0005), patience 36/1500\n",
            "Epoch 235/750 - Train Loss: 0.0257 - Val Loss: 3.4323\n",
            "Validation loss increased (3.4323), patience 37/1500\n",
            "Epoch 236/750 - Train Loss: 0.0251 - Val Loss: 4.3881\n",
            "Validation loss increased (4.3881), patience 38/1500\n",
            "Epoch 237/750 - Train Loss: 0.0248 - Val Loss: 3.5564\n",
            "Validation loss increased (3.5564), patience 39/1500\n",
            "Epoch 238/750 - Train Loss: 0.0259 - Val Loss: 3.2415\n",
            "Validation loss increased (3.2415), patience 40/1500\n",
            "Epoch 239/750 - Train Loss: 0.0253 - Val Loss: 3.7626\n",
            "Validation loss increased (3.7626), patience 41/1500\n",
            "Epoch 240/750 - Train Loss: 0.0254 - Val Loss: 3.5425\n",
            "Validation loss increased (3.5425), patience 42/1500\n",
            "Epoch 241/750 - Train Loss: 0.0247 - Val Loss: 3.9504\n",
            "Validation loss increased (3.9504), patience 43/1500\n",
            "Epoch 242/750 - Train Loss: 0.0250 - Val Loss: 3.6369\n",
            "Validation loss increased (3.6369), patience 44/1500\n",
            "Epoch 243/750 - Train Loss: 0.0252 - Val Loss: 5.0223\n",
            "Validation loss increased (5.0223), patience 45/1500\n",
            "Epoch 244/750 - Train Loss: 0.0253 - Val Loss: 3.0005\n",
            "Validation loss increased (3.0005), patience 46/1500\n",
            "Epoch 245/750 - Train Loss: 0.0254 - Val Loss: 4.8728\n",
            "Validation loss increased (4.8728), patience 47/1500\n",
            "Epoch 246/750 - Train Loss: 0.0248 - Val Loss: 3.0604\n",
            "Validation loss increased (3.0604), patience 48/1500\n",
            "Epoch 247/750 - Train Loss: 0.0252 - Val Loss: 3.4985\n",
            "Validation loss increased (3.4985), patience 49/1500\n",
            "Epoch 248/750 - Train Loss: 0.0246 - Val Loss: 3.1249\n",
            "Validation loss increased (3.1249), patience 50/1500\n",
            "Epoch 249/750 - Train Loss: 0.0252 - Val Loss: 3.3041\n",
            "Validation loss increased (3.3041), patience 51/1500\n",
            "Epoch 250/750 - Train Loss: 0.0249 - Val Loss: 3.1144\n",
            "Validation loss increased (3.1144), patience 52/1500\n",
            "Epoch 251/750 - Train Loss: 0.0246 - Val Loss: 4.9399\n",
            "Validation loss increased (4.9399), patience 53/1500\n",
            "Epoch 252/750 - Train Loss: 0.0254 - Val Loss: 3.8490\n",
            "Validation loss increased (3.8490), patience 54/1500\n",
            "Epoch 253/750 - Train Loss: 0.0252 - Val Loss: 3.7806\n",
            "Validation loss increased (3.7806), patience 55/1500\n",
            "Epoch 254/750 - Train Loss: 0.0253 - Val Loss: 3.8717\n",
            "Validation loss increased (3.8717), patience 56/1500\n",
            "Epoch 255/750 - Train Loss: 0.0247 - Val Loss: 3.6528\n",
            "Validation loss increased (3.6528), patience 57/1500\n",
            "Epoch 256/750 - Train Loss: 0.0257 - Val Loss: 4.1330\n",
            "Validation loss increased (4.1330), patience 58/1500\n",
            "Epoch 257/750 - Train Loss: 0.0250 - Val Loss: 3.7601\n",
            "Validation loss increased (3.7601), patience 59/1500\n",
            "Epoch 258/750 - Train Loss: 0.0244 - Val Loss: 3.8957\n",
            "Validation loss increased (3.8957), patience 60/1500\n",
            "Epoch 259/750 - Train Loss: 0.0246 - Val Loss: 3.6098\n",
            "Validation loss increased (3.6098), patience 61/1500\n",
            "Epoch 260/750 - Train Loss: 0.0246 - Val Loss: 4.9557\n",
            "Validation loss increased (4.9557), patience 62/1500\n",
            "Epoch 261/750 - Train Loss: 0.0245 - Val Loss: 3.2793\n",
            "Validation loss increased (3.2793), patience 63/1500\n",
            "Epoch 262/750 - Train Loss: 0.0248 - Val Loss: 2.9366\n",
            "Validation loss increased (2.9366), patience 64/1500\n",
            "Epoch 263/750 - Train Loss: 0.0248 - Val Loss: 3.2199\n",
            "Validation loss increased (3.2199), patience 65/1500\n",
            "Epoch 264/750 - Train Loss: 0.0255 - Val Loss: 4.4220\n",
            "Validation loss increased (4.4220), patience 66/1500\n",
            "Epoch 265/750 - Train Loss: 0.0256 - Val Loss: 3.1568\n",
            "Validation loss increased (3.1568), patience 67/1500\n",
            "Epoch 266/750 - Train Loss: 0.0254 - Val Loss: 4.0522\n",
            "Validation loss increased (4.0522), patience 68/1500\n",
            "Epoch 267/750 - Train Loss: 0.0266 - Val Loss: 3.9850\n",
            "Validation loss increased (3.9850), patience 69/1500\n",
            "Epoch 268/750 - Train Loss: 0.0247 - Val Loss: 3.2329\n",
            "Validation loss increased (3.2329), patience 70/1500\n",
            "Epoch 269/750 - Train Loss: 0.0244 - Val Loss: 3.1418\n",
            "Validation loss increased (3.1418), patience 71/1500\n",
            "Epoch 270/750 - Train Loss: 0.0243 - Val Loss: 3.1676\n",
            "Validation loss increased (3.1676), patience 72/1500\n",
            "Epoch 271/750 - Train Loss: 0.0262 - Val Loss: 3.9657\n",
            "Validation loss increased (3.9657), patience 73/1500\n",
            "Epoch 272/750 - Train Loss: 0.0248 - Val Loss: 3.1647\n",
            "Validation loss increased (3.1647), patience 74/1500\n",
            "Epoch 273/750 - Train Loss: 0.0249 - Val Loss: 3.4963\n",
            "Validation loss increased (3.4963), patience 75/1500\n",
            "Epoch 274/750 - Train Loss: 0.0242 - Val Loss: 5.6517\n",
            "Validation loss increased (5.6517), patience 76/1500\n",
            "Epoch 275/750 - Train Loss: 0.0251 - Val Loss: 3.9575\n",
            "Validation loss increased (3.9575), patience 77/1500\n",
            "Epoch 276/750 - Train Loss: 0.0243 - Val Loss: 3.4641\n",
            "Validation loss increased (3.4641), patience 78/1500\n",
            "Epoch 277/750 - Train Loss: 0.0249 - Val Loss: 3.0799\n",
            "Validation loss increased (3.0799), patience 79/1500\n",
            "Epoch 278/750 - Train Loss: 0.0249 - Val Loss: 3.5965\n",
            "Validation loss increased (3.5965), patience 80/1500\n",
            "Epoch 279/750 - Train Loss: 0.0246 - Val Loss: 3.3471\n",
            "Validation loss increased (3.3471), patience 81/1500\n",
            "Epoch 280/750 - Train Loss: 0.0241 - Val Loss: 3.3452\n",
            "Validation loss increased (3.3452), patience 82/1500\n",
            "Epoch 281/750 - Train Loss: 0.0245 - Val Loss: 6.5793\n",
            "Validation loss increased (6.5793), patience 83/1500\n",
            "Epoch 282/750 - Train Loss: 0.0249 - Val Loss: 4.3173\n",
            "Validation loss increased (4.3173), patience 84/1500\n",
            "Epoch 283/750 - Train Loss: 0.0244 - Val Loss: 3.7858\n",
            "Validation loss increased (3.7858), patience 85/1500\n",
            "Epoch 284/750 - Train Loss: 0.0243 - Val Loss: 3.4076\n",
            "Validation loss increased (3.4076), patience 86/1500\n",
            "Epoch 285/750 - Train Loss: 0.0242 - Val Loss: 3.6822\n",
            "Validation loss increased (3.6822), patience 87/1500\n",
            "Epoch 286/750 - Train Loss: 0.0248 - Val Loss: 3.8738\n",
            "Validation loss increased (3.8738), patience 88/1500\n",
            "Epoch 287/750 - Train Loss: 0.0244 - Val Loss: 4.5803\n",
            "Validation loss increased (4.5803), patience 89/1500\n",
            "Epoch 288/750 - Train Loss: 0.0278 - Val Loss: 4.6733\n",
            "Validation loss increased (4.6733), patience 90/1500\n",
            "Epoch 289/750 - Train Loss: 0.0385 - Val Loss: 4.7172\n",
            "Validation loss increased (4.7172), patience 91/1500\n",
            "Epoch 290/750 - Train Loss: 0.0330 - Val Loss: 3.8345\n",
            "Validation loss increased (3.8345), patience 92/1500\n",
            "Epoch 291/750 - Train Loss: 0.0345 - Val Loss: 4.0315\n",
            "Validation loss increased (4.0315), patience 93/1500\n",
            "Epoch 292/750 - Train Loss: 0.0319 - Val Loss: 4.3869\n",
            "Validation loss increased (4.3869), patience 94/1500\n",
            "Epoch 293/750 - Train Loss: 0.0304 - Val Loss: 4.2483\n",
            "Validation loss increased (4.2483), patience 95/1500\n",
            "Epoch 294/750 - Train Loss: 0.0298 - Val Loss: 4.1764\n",
            "Validation loss increased (4.1764), patience 96/1500\n",
            "Epoch 295/750 - Train Loss: 0.0290 - Val Loss: 3.8367\n",
            "Validation loss increased (3.8367), patience 97/1500\n",
            "Epoch 296/750 - Train Loss: 0.0282 - Val Loss: 3.9391\n",
            "Validation loss increased (3.9391), patience 98/1500\n",
            "Epoch 297/750 - Train Loss: 0.0279 - Val Loss: 2.7675\n",
            "Validation loss increased (2.7675), patience 99/1500\n",
            "Epoch 298/750 - Train Loss: 0.0291 - Val Loss: 3.4542\n",
            "Validation loss increased (3.4542), patience 100/1500\n",
            "Epoch 299/750 - Train Loss: 0.0280 - Val Loss: 3.6696\n",
            "Validation loss increased (3.6696), patience 101/1500\n",
            "Epoch 300/750 - Train Loss: 0.0275 - Val Loss: 2.9565\n",
            "Validation loss increased (2.9565), patience 102/1500\n",
            "Epoch 301/750 - Train Loss: 0.0271 - Val Loss: 3.5590\n",
            "Validation loss increased (3.5590), patience 103/1500\n",
            "Epoch 302/750 - Train Loss: 0.0273 - Val Loss: 4.6385\n",
            "Validation loss increased (4.6385), patience 104/1500\n",
            "Epoch 303/750 - Train Loss: 0.0275 - Val Loss: 3.2383\n",
            "Validation loss increased (3.2383), patience 105/1500\n",
            "Epoch 304/750 - Train Loss: 0.0265 - Val Loss: 4.2964\n",
            "Validation loss increased (4.2964), patience 106/1500\n",
            "Epoch 305/750 - Train Loss: 0.0265 - Val Loss: 3.3266\n",
            "Validation loss increased (3.3266), patience 107/1500\n",
            "Epoch 306/750 - Train Loss: 0.0266 - Val Loss: 3.6017\n",
            "Validation loss increased (3.6017), patience 108/1500\n",
            "Epoch 307/750 - Train Loss: 0.0262 - Val Loss: 4.7771\n",
            "Validation loss increased (4.7771), patience 109/1500\n",
            "Epoch 308/750 - Train Loss: 0.0261 - Val Loss: 3.6539\n",
            "Validation loss increased (3.6539), patience 110/1500\n",
            "Epoch 309/750 - Train Loss: 0.0260 - Val Loss: 3.1621\n",
            "Validation loss increased (3.1621), patience 111/1500\n",
            "Epoch 310/750 - Train Loss: 0.0257 - Val Loss: 4.0902\n",
            "Validation loss increased (4.0902), patience 112/1500\n",
            "Epoch 311/750 - Train Loss: 0.0259 - Val Loss: 5.3980\n",
            "Validation loss increased (5.3980), patience 113/1500\n",
            "Epoch 312/750 - Train Loss: 0.0252 - Val Loss: 3.1243\n",
            "Validation loss increased (3.1243), patience 114/1500\n",
            "Epoch 313/750 - Train Loss: 0.0249 - Val Loss: 2.7833\n",
            "Validation loss increased (2.7833), patience 115/1500\n",
            "Epoch 314/750 - Train Loss: 0.0248 - Val Loss: 3.1289\n",
            "Validation loss increased (3.1289), patience 116/1500\n",
            "Epoch 315/750 - Train Loss: 0.0306 - Val Loss: 4.5620\n",
            "Validation loss increased (4.5620), patience 117/1500\n",
            "Epoch 316/750 - Train Loss: 0.0287 - Val Loss: 3.6128\n",
            "Validation loss increased (3.6128), patience 118/1500\n",
            "Epoch 317/750 - Train Loss: 0.0269 - Val Loss: 3.1055\n",
            "Validation loss increased (3.1055), patience 119/1500\n",
            "Epoch 318/750 - Train Loss: 0.0261 - Val Loss: 3.5717\n",
            "Validation loss increased (3.5717), patience 120/1500\n",
            "Epoch 319/750 - Train Loss: 0.0261 - Val Loss: 3.1339\n",
            "Validation loss increased (3.1339), patience 121/1500\n",
            "Epoch 320/750 - Train Loss: 0.0257 - Val Loss: 4.4857\n",
            "Validation loss increased (4.4857), patience 122/1500\n",
            "Epoch 321/750 - Train Loss: 0.0255 - Val Loss: 4.5225\n",
            "Validation loss increased (4.5225), patience 123/1500\n",
            "Epoch 322/750 - Train Loss: 0.0256 - Val Loss: 3.2248\n",
            "Validation loss increased (3.2248), patience 124/1500\n",
            "Epoch 323/750 - Train Loss: 0.0256 - Val Loss: 3.1867\n",
            "Validation loss increased (3.1867), patience 125/1500\n",
            "Epoch 324/750 - Train Loss: 0.0264 - Val Loss: 7.4250\n",
            "Validation loss increased (7.4250), patience 126/1500\n",
            "Epoch 325/750 - Train Loss: 0.0343 - Val Loss: 4.0850\n",
            "Validation loss increased (4.0850), patience 127/1500\n",
            "Epoch 326/750 - Train Loss: 0.0307 - Val Loss: 4.2681\n",
            "Validation loss increased (4.2681), patience 128/1500\n",
            "Epoch 327/750 - Train Loss: 0.0285 - Val Loss: 3.5492\n",
            "Validation loss increased (3.5492), patience 129/1500\n",
            "Epoch 328/750 - Train Loss: 0.0283 - Val Loss: 4.0737\n",
            "Validation loss increased (4.0737), patience 130/1500\n",
            "Epoch 329/750 - Train Loss: 0.0275 - Val Loss: 3.9029\n",
            "Validation loss increased (3.9029), patience 131/1500\n",
            "Epoch 330/750 - Train Loss: 0.0271 - Val Loss: 4.1290\n",
            "Validation loss increased (4.1290), patience 132/1500\n",
            "Epoch 331/750 - Train Loss: 0.0264 - Val Loss: 3.3155\n",
            "Validation loss increased (3.3155), patience 133/1500\n",
            "Epoch 332/750 - Train Loss: 0.0269 - Val Loss: 3.7503\n",
            "Validation loss increased (3.7503), patience 134/1500\n",
            "Epoch 333/750 - Train Loss: 0.0266 - Val Loss: 3.9391\n",
            "Validation loss increased (3.9391), patience 135/1500\n",
            "Epoch 334/750 - Train Loss: 0.0306 - Val Loss: 3.8958\n",
            "Validation loss increased (3.8958), patience 136/1500\n",
            "Epoch 335/750 - Train Loss: 0.0286 - Val Loss: 5.1538\n",
            "Validation loss increased (5.1538), patience 137/1500\n",
            "Epoch 336/750 - Train Loss: 0.0277 - Val Loss: 3.2228\n",
            "Validation loss increased (3.2228), patience 138/1500\n",
            "Epoch 337/750 - Train Loss: 0.0266 - Val Loss: 4.2492\n",
            "Validation loss increased (4.2492), patience 139/1500\n",
            "Epoch 338/750 - Train Loss: 0.0269 - Val Loss: 3.1725\n",
            "Validation loss increased (3.1725), patience 140/1500\n",
            "Epoch 339/750 - Train Loss: 0.0261 - Val Loss: 3.2584\n",
            "Validation loss increased (3.2584), patience 141/1500\n",
            "Epoch 340/750 - Train Loss: 0.0260 - Val Loss: 3.4996\n",
            "Validation loss increased (3.4996), patience 142/1500\n",
            "Epoch 341/750 - Train Loss: 0.0275 - Val Loss: 3.1640\n",
            "Validation loss increased (3.1640), patience 143/1500\n",
            "Epoch 342/750 - Train Loss: 0.0276 - Val Loss: 4.1699\n",
            "Validation loss increased (4.1699), patience 144/1500\n",
            "Epoch 343/750 - Train Loss: 0.0263 - Val Loss: 3.9258\n",
            "Validation loss increased (3.9258), patience 145/1500\n",
            "Epoch 344/750 - Train Loss: 0.0259 - Val Loss: 3.6707\n",
            "Validation loss increased (3.6707), patience 146/1500\n",
            "Epoch 345/750 - Train Loss: 0.0257 - Val Loss: 3.0368\n",
            "Validation loss increased (3.0368), patience 147/1500\n",
            "Epoch 346/750 - Train Loss: 0.0254 - Val Loss: 3.1213\n",
            "Validation loss increased (3.1213), patience 148/1500\n",
            "Epoch 347/750 - Train Loss: 0.0255 - Val Loss: 4.2527\n",
            "Validation loss increased (4.2527), patience 149/1500\n",
            "Epoch 348/750 - Train Loss: 0.0257 - Val Loss: 3.0294\n",
            "Validation loss increased (3.0294), patience 150/1500\n",
            "Epoch 349/750 - Train Loss: 0.0259 - Val Loss: 3.4723\n",
            "Validation loss increased (3.4723), patience 151/1500\n",
            "Epoch 350/750 - Train Loss: 0.0276 - Val Loss: 3.7243\n",
            "Validation loss increased (3.7243), patience 152/1500\n",
            "Epoch 351/750 - Train Loss: 0.0265 - Val Loss: 3.0396\n",
            "Validation loss increased (3.0396), patience 153/1500\n",
            "Epoch 352/750 - Train Loss: 0.0260 - Val Loss: 3.3736\n",
            "Validation loss increased (3.3736), patience 154/1500\n",
            "Epoch 353/750 - Train Loss: 0.0261 - Val Loss: 3.8669\n",
            "Validation loss increased (3.8669), patience 155/1500\n",
            "Epoch 354/750 - Train Loss: 0.0257 - Val Loss: 3.3869\n",
            "Validation loss increased (3.3869), patience 156/1500\n",
            "Epoch 355/750 - Train Loss: 0.0254 - Val Loss: 3.2679\n",
            "Validation loss increased (3.2679), patience 157/1500\n",
            "Epoch 356/750 - Train Loss: 0.0256 - Val Loss: 3.2799\n",
            "Validation loss increased (3.2799), patience 158/1500\n",
            "Epoch 357/750 - Train Loss: 0.0254 - Val Loss: 3.5911\n",
            "Validation loss increased (3.5911), patience 159/1500\n",
            "Epoch 358/750 - Train Loss: 0.0255 - Val Loss: 4.6245\n",
            "Validation loss increased (4.6245), patience 160/1500\n",
            "Epoch 359/750 - Train Loss: 0.0337 - Val Loss: 4.5303\n",
            "Validation loss increased (4.5303), patience 161/1500\n",
            "Epoch 360/750 - Train Loss: 0.0341 - Val Loss: 4.1772\n",
            "Validation loss increased (4.1772), patience 162/1500\n",
            "Epoch 361/750 - Train Loss: 0.0332 - Val Loss: 5.8229\n",
            "Validation loss increased (5.8229), patience 163/1500\n",
            "Epoch 362/750 - Train Loss: 0.0313 - Val Loss: 3.9378\n",
            "Validation loss increased (3.9378), patience 164/1500\n",
            "Epoch 363/750 - Train Loss: 0.0304 - Val Loss: 3.7683\n",
            "Validation loss increased (3.7683), patience 165/1500\n",
            "Epoch 364/750 - Train Loss: 0.0300 - Val Loss: 3.3143\n",
            "Validation loss increased (3.3143), patience 166/1500\n",
            "Epoch 365/750 - Train Loss: 0.0301 - Val Loss: 5.6406\n",
            "Validation loss increased (5.6406), patience 167/1500\n",
            "Epoch 366/750 - Train Loss: 0.0308 - Val Loss: 4.5180\n",
            "Validation loss increased (4.5180), patience 168/1500\n",
            "Epoch 367/750 - Train Loss: 0.0295 - Val Loss: 4.0736\n",
            "Validation loss increased (4.0736), patience 169/1500\n",
            "Epoch 368/750 - Train Loss: 0.0288 - Val Loss: 4.1009\n",
            "Validation loss increased (4.1009), patience 170/1500\n",
            "Epoch 369/750 - Train Loss: 0.0287 - Val Loss: 3.9187\n",
            "Validation loss increased (3.9187), patience 171/1500\n",
            "Epoch 370/750 - Train Loss: 0.0285 - Val Loss: 4.6594\n",
            "Validation loss increased (4.6594), patience 172/1500\n",
            "Epoch 371/750 - Train Loss: 0.0290 - Val Loss: 3.8180\n",
            "Validation loss increased (3.8180), patience 173/1500\n",
            "Epoch 372/750 - Train Loss: 0.0289 - Val Loss: 3.2279\n",
            "Validation loss increased (3.2279), patience 174/1500\n",
            "Epoch 373/750 - Train Loss: 0.0291 - Val Loss: 4.0263\n",
            "Validation loss increased (4.0263), patience 175/1500\n",
            "Epoch 374/750 - Train Loss: 0.0285 - Val Loss: 4.8657\n",
            "Validation loss increased (4.8657), patience 176/1500\n",
            "Epoch 375/750 - Train Loss: 0.0284 - Val Loss: 3.6251\n",
            "Validation loss increased (3.6251), patience 177/1500\n",
            "Epoch 376/750 - Train Loss: 0.0294 - Val Loss: 4.7351\n",
            "Validation loss increased (4.7351), patience 178/1500\n",
            "Epoch 377/750 - Train Loss: 0.0292 - Val Loss: 3.6007\n",
            "Validation loss increased (3.6007), patience 179/1500\n",
            "Epoch 378/750 - Train Loss: 0.0298 - Val Loss: 3.5207\n",
            "Validation loss increased (3.5207), patience 180/1500\n",
            "Epoch 379/750 - Train Loss: 0.0293 - Val Loss: 3.5685\n",
            "Validation loss increased (3.5685), patience 181/1500\n",
            "Epoch 380/750 - Train Loss: 0.0291 - Val Loss: 2.9707\n",
            "Validation loss increased (2.9707), patience 182/1500\n",
            "Epoch 381/750 - Train Loss: 0.0290 - Val Loss: 4.2676\n",
            "Validation loss increased (4.2676), patience 183/1500\n",
            "Epoch 382/750 - Train Loss: 0.0291 - Val Loss: 3.2282\n",
            "Validation loss increased (3.2282), patience 184/1500\n",
            "Epoch 383/750 - Train Loss: 0.0288 - Val Loss: 3.4329\n",
            "Validation loss increased (3.4329), patience 185/1500\n",
            "Epoch 384/750 - Train Loss: 0.0289 - Val Loss: 3.8466\n",
            "Validation loss increased (3.8466), patience 186/1500\n",
            "Epoch 385/750 - Train Loss: 0.0289 - Val Loss: 2.9433\n",
            "Validation loss increased (2.9433), patience 187/1500\n",
            "Epoch 386/750 - Train Loss: 0.0280 - Val Loss: 2.8629\n",
            "Validation loss increased (2.8629), patience 188/1500\n",
            "Epoch 387/750 - Train Loss: 0.0284 - Val Loss: 2.7958\n",
            "Validation loss increased (2.7958), patience 189/1500\n",
            "Epoch 388/750 - Train Loss: 0.0289 - Val Loss: 3.9339\n",
            "Validation loss increased (3.9339), patience 190/1500\n",
            "Epoch 389/750 - Train Loss: 0.0280 - Val Loss: 3.0439\n",
            "Validation loss increased (3.0439), patience 191/1500\n",
            "Epoch 390/750 - Train Loss: 0.0279 - Val Loss: 3.4731\n",
            "Validation loss increased (3.4731), patience 192/1500\n",
            "Epoch 391/750 - Train Loss: 0.0283 - Val Loss: 3.3416\n",
            "Validation loss increased (3.3416), patience 193/1500\n",
            "Epoch 392/750 - Train Loss: 0.0294 - Val Loss: 3.5582\n",
            "Validation loss increased (3.5582), patience 194/1500\n",
            "Epoch 393/750 - Train Loss: 0.0285 - Val Loss: 3.3433\n",
            "Validation loss increased (3.3433), patience 195/1500\n",
            "Epoch 394/750 - Train Loss: 0.0278 - Val Loss: 3.3430\n",
            "Validation loss increased (3.3430), patience 196/1500\n",
            "Epoch 395/750 - Train Loss: 0.0274 - Val Loss: 3.7270\n",
            "Validation loss increased (3.7270), patience 197/1500\n",
            "Epoch 396/750 - Train Loss: 0.0274 - Val Loss: 3.3870\n",
            "Validation loss increased (3.3870), patience 198/1500\n",
            "Epoch 397/750 - Train Loss: 0.0274 - Val Loss: 3.6237\n",
            "Validation loss increased (3.6237), patience 199/1500\n",
            "Epoch 398/750 - Train Loss: 0.0272 - Val Loss: 3.6954\n",
            "Validation loss increased (3.6954), patience 200/1500\n",
            "Epoch 399/750 - Train Loss: 0.0278 - Val Loss: 3.2918\n",
            "Validation loss increased (3.2918), patience 201/1500\n",
            "Epoch 400/750 - Train Loss: 0.0291 - Val Loss: 4.1939\n",
            "Validation loss increased (4.1939), patience 202/1500\n",
            "Epoch 401/750 - Train Loss: 0.0271 - Val Loss: 3.6600\n",
            "Validation loss increased (3.6600), patience 203/1500\n",
            "Epoch 402/750 - Train Loss: 0.0279 - Val Loss: 5.5680\n",
            "Validation loss increased (5.5680), patience 204/1500\n",
            "Epoch 403/750 - Train Loss: 0.0275 - Val Loss: 3.4249\n",
            "Validation loss increased (3.4249), patience 205/1500\n",
            "Epoch 404/750 - Train Loss: 0.0273 - Val Loss: 3.7429\n",
            "Validation loss increased (3.7429), patience 206/1500\n",
            "Epoch 405/750 - Train Loss: 0.0272 - Val Loss: 3.7349\n",
            "Validation loss increased (3.7349), patience 207/1500\n",
            "Epoch 406/750 - Train Loss: 0.0289 - Val Loss: 3.3493\n",
            "Validation loss increased (3.3493), patience 208/1500\n",
            "Epoch 407/750 - Train Loss: 0.0287 - Val Loss: 3.3545\n",
            "Validation loss increased (3.3545), patience 209/1500\n",
            "Epoch 408/750 - Train Loss: 0.0296 - Val Loss: 3.5767\n",
            "Validation loss increased (3.5767), patience 210/1500\n",
            "Epoch 409/750 - Train Loss: 0.0278 - Val Loss: 3.0396\n",
            "Validation loss increased (3.0396), patience 211/1500\n",
            "Epoch 410/750 - Train Loss: 0.0273 - Val Loss: 3.2368\n",
            "Validation loss increased (3.2368), patience 212/1500\n",
            "Epoch 411/750 - Train Loss: 0.0270 - Val Loss: 3.4428\n",
            "Validation loss increased (3.4428), patience 213/1500\n",
            "Epoch 412/750 - Train Loss: 0.0278 - Val Loss: 3.7188\n",
            "Validation loss increased (3.7188), patience 214/1500\n",
            "Epoch 413/750 - Train Loss: 0.0271 - Val Loss: 4.7916\n",
            "Validation loss increased (4.7916), patience 215/1500\n",
            "Epoch 414/750 - Train Loss: 0.0275 - Val Loss: 3.9994\n",
            "Validation loss increased (3.9994), patience 216/1500\n",
            "Epoch 415/750 - Train Loss: 0.0278 - Val Loss: 3.9857\n",
            "Validation loss increased (3.9857), patience 217/1500\n",
            "Epoch 416/750 - Train Loss: 0.0273 - Val Loss: 3.3396\n",
            "Validation loss increased (3.3396), patience 218/1500\n",
            "Epoch 417/750 - Train Loss: 0.0270 - Val Loss: 3.7742\n",
            "Validation loss increased (3.7742), patience 219/1500\n",
            "Epoch 418/750 - Train Loss: 0.0276 - Val Loss: 4.2468\n",
            "Validation loss increased (4.2468), patience 220/1500\n",
            "Epoch 419/750 - Train Loss: 0.0281 - Val Loss: 3.7370\n",
            "Validation loss increased (3.7370), patience 221/1500\n",
            "Epoch 420/750 - Train Loss: 0.0288 - Val Loss: 3.6824\n",
            "Validation loss increased (3.6824), patience 222/1500\n",
            "Epoch 421/750 - Train Loss: 0.0281 - Val Loss: 3.6155\n",
            "Validation loss increased (3.6155), patience 223/1500\n",
            "Epoch 422/750 - Train Loss: 0.0288 - Val Loss: 3.7281\n",
            "Validation loss increased (3.7281), patience 224/1500\n",
            "Epoch 423/750 - Train Loss: 0.0346 - Val Loss: 4.3054\n",
            "Validation loss increased (4.3054), patience 225/1500\n",
            "Epoch 424/750 - Train Loss: 0.0312 - Val Loss: 3.3643\n",
            "Validation loss increased (3.3643), patience 226/1500\n",
            "Epoch 425/750 - Train Loss: 0.0284 - Val Loss: 3.9353\n",
            "Validation loss increased (3.9353), patience 227/1500\n",
            "Epoch 426/750 - Train Loss: 0.0282 - Val Loss: 3.6650\n",
            "Validation loss increased (3.6650), patience 228/1500\n",
            "Epoch 427/750 - Train Loss: 0.0276 - Val Loss: 3.2959\n",
            "Validation loss increased (3.2959), patience 229/1500\n",
            "Epoch 428/750 - Train Loss: 0.0275 - Val Loss: 4.0550\n",
            "Validation loss increased (4.0550), patience 230/1500\n",
            "Epoch 429/750 - Train Loss: 0.0272 - Val Loss: 3.3831\n",
            "Validation loss increased (3.3831), patience 231/1500\n",
            "Epoch 430/750 - Train Loss: 0.0272 - Val Loss: 3.0594\n",
            "Validation loss increased (3.0594), patience 232/1500\n",
            "Epoch 431/750 - Train Loss: 0.0276 - Val Loss: 3.5230\n",
            "Validation loss increased (3.5230), patience 233/1500\n",
            "Epoch 432/750 - Train Loss: 0.0287 - Val Loss: 3.3927\n",
            "Validation loss increased (3.3927), patience 234/1500\n",
            "Epoch 433/750 - Train Loss: 0.0285 - Val Loss: 3.0631\n",
            "Validation loss increased (3.0631), patience 235/1500\n",
            "Epoch 434/750 - Train Loss: 0.0283 - Val Loss: 3.5369\n",
            "Validation loss increased (3.5369), patience 236/1500\n",
            "Epoch 435/750 - Train Loss: 0.0275 - Val Loss: 3.3096\n",
            "Validation loss increased (3.3096), patience 237/1500\n",
            "Epoch 436/750 - Train Loss: 0.0266 - Val Loss: 3.5781\n",
            "Validation loss increased (3.5781), patience 238/1500\n",
            "Epoch 437/750 - Train Loss: 0.0265 - Val Loss: 4.0022\n",
            "Validation loss increased (4.0022), patience 239/1500\n",
            "Epoch 438/750 - Train Loss: 0.0271 - Val Loss: 3.2133\n",
            "Validation loss increased (3.2133), patience 240/1500\n",
            "Epoch 439/750 - Train Loss: 0.0265 - Val Loss: 4.2406\n",
            "Validation loss increased (4.2406), patience 241/1500\n",
            "Epoch 440/750 - Train Loss: 0.0278 - Val Loss: 4.2056\n",
            "Validation loss increased (4.2056), patience 242/1500\n",
            "Epoch 441/750 - Train Loss: 0.0266 - Val Loss: 4.0801\n",
            "Validation loss increased (4.0801), patience 243/1500\n",
            "Epoch 442/750 - Train Loss: 0.0266 - Val Loss: 2.7926\n",
            "Validation loss increased (2.7926), patience 244/1500\n",
            "Epoch 443/750 - Train Loss: 0.0266 - Val Loss: 3.4788\n",
            "Validation loss increased (3.4788), patience 245/1500\n",
            "Epoch 444/750 - Train Loss: 0.0273 - Val Loss: 3.9683\n",
            "Validation loss increased (3.9683), patience 246/1500\n",
            "Epoch 445/750 - Train Loss: 0.0264 - Val Loss: 3.7298\n",
            "Validation loss increased (3.7298), patience 247/1500\n",
            "Epoch 446/750 - Train Loss: 0.0267 - Val Loss: 3.7218\n",
            "Validation loss increased (3.7218), patience 248/1500\n",
            "Epoch 447/750 - Train Loss: 0.0267 - Val Loss: 3.9713\n",
            "Validation loss increased (3.9713), patience 249/1500\n",
            "Epoch 448/750 - Train Loss: 0.0261 - Val Loss: 3.7982\n",
            "Validation loss increased (3.7982), patience 250/1500\n",
            "Epoch 449/750 - Train Loss: 0.0265 - Val Loss: 3.3702\n",
            "Validation loss increased (3.3702), patience 251/1500\n",
            "Epoch 450/750 - Train Loss: 0.0271 - Val Loss: 2.9928\n",
            "Validation loss increased (2.9928), patience 252/1500\n",
            "Epoch 451/750 - Train Loss: 0.0265 - Val Loss: 3.9129\n",
            "Validation loss increased (3.9129), patience 253/1500\n",
            "Epoch 452/750 - Train Loss: 0.0268 - Val Loss: 3.5175\n",
            "Validation loss increased (3.5175), patience 254/1500\n",
            "Epoch 453/750 - Train Loss: 0.0267 - Val Loss: 3.7324\n",
            "Validation loss increased (3.7324), patience 255/1500\n",
            "Epoch 454/750 - Train Loss: 0.0265 - Val Loss: 3.4763\n",
            "Validation loss increased (3.4763), patience 256/1500\n",
            "Epoch 455/750 - Train Loss: 0.0266 - Val Loss: 4.3991\n",
            "Validation loss increased (4.3991), patience 257/1500\n",
            "Epoch 456/750 - Train Loss: 0.0260 - Val Loss: 4.5812\n",
            "Validation loss increased (4.5812), patience 258/1500\n",
            "Epoch 457/750 - Train Loss: 0.0261 - Val Loss: 3.6255\n",
            "Validation loss increased (3.6255), patience 259/1500\n",
            "Epoch 458/750 - Train Loss: 0.0264 - Val Loss: 3.5247\n",
            "Validation loss increased (3.5247), patience 260/1500\n",
            "Epoch 459/750 - Train Loss: 0.0261 - Val Loss: 5.6467\n",
            "Validation loss increased (5.6467), patience 261/1500\n",
            "Epoch 460/750 - Train Loss: 0.0263 - Val Loss: 3.3839\n",
            "Validation loss increased (3.3839), patience 262/1500\n",
            "Epoch 461/750 - Train Loss: 0.0268 - Val Loss: 3.1843\n",
            "Validation loss increased (3.1843), patience 263/1500\n",
            "Epoch 462/750 - Train Loss: 0.0262 - Val Loss: 3.2336\n",
            "Validation loss increased (3.2336), patience 264/1500\n",
            "Epoch 463/750 - Train Loss: 0.0265 - Val Loss: 3.4560\n",
            "Validation loss increased (3.4560), patience 265/1500\n",
            "Epoch 464/750 - Train Loss: 0.0259 - Val Loss: 3.7897\n",
            "Validation loss increased (3.7897), patience 266/1500\n",
            "Epoch 465/750 - Train Loss: 0.0262 - Val Loss: 3.2127\n",
            "Validation loss increased (3.2127), patience 267/1500\n",
            "Epoch 466/750 - Train Loss: 0.0265 - Val Loss: 3.2875\n",
            "Validation loss increased (3.2875), patience 268/1500\n",
            "Epoch 467/750 - Train Loss: 0.0264 - Val Loss: 3.9821\n",
            "Validation loss increased (3.9821), patience 269/1500\n",
            "Epoch 468/750 - Train Loss: 0.0260 - Val Loss: 3.0079\n",
            "Validation loss increased (3.0079), patience 270/1500\n",
            "Epoch 469/750 - Train Loss: 0.0260 - Val Loss: 3.5223\n",
            "Validation loss increased (3.5223), patience 271/1500\n",
            "Epoch 470/750 - Train Loss: 0.0257 - Val Loss: 3.7641\n",
            "Validation loss increased (3.7641), patience 272/1500\n",
            "Epoch 471/750 - Train Loss: 0.0258 - Val Loss: 3.8225\n",
            "Validation loss increased (3.8225), patience 273/1500\n",
            "Epoch 472/750 - Train Loss: 0.0260 - Val Loss: 3.3034\n",
            "Validation loss increased (3.3034), patience 274/1500\n",
            "Epoch 473/750 - Train Loss: 0.0253 - Val Loss: 4.4475\n",
            "Validation loss increased (4.4475), patience 275/1500\n",
            "Epoch 474/750 - Train Loss: 0.0258 - Val Loss: 3.8096\n",
            "Validation loss increased (3.8096), patience 276/1500\n",
            "Epoch 475/750 - Train Loss: 0.0254 - Val Loss: 3.8375\n",
            "Validation loss increased (3.8375), patience 277/1500\n",
            "Epoch 476/750 - Train Loss: 0.0261 - Val Loss: 4.3503\n",
            "Validation loss increased (4.3503), patience 278/1500\n",
            "Epoch 477/750 - Train Loss: 0.0256 - Val Loss: 4.4437\n",
            "Validation loss increased (4.4437), patience 279/1500\n",
            "Epoch 478/750 - Train Loss: 0.0257 - Val Loss: 4.0989\n",
            "Validation loss increased (4.0989), patience 280/1500\n",
            "Epoch 479/750 - Train Loss: 0.0258 - Val Loss: 3.3701\n",
            "Validation loss increased (3.3701), patience 281/1500\n",
            "Epoch 480/750 - Train Loss: 0.0255 - Val Loss: 3.4607\n",
            "Validation loss increased (3.4607), patience 282/1500\n",
            "Epoch 481/750 - Train Loss: 0.0253 - Val Loss: 5.2093\n",
            "Validation loss increased (5.2093), patience 283/1500\n",
            "Epoch 482/750 - Train Loss: 0.0255 - Val Loss: 3.4096\n",
            "Validation loss increased (3.4096), patience 284/1500\n",
            "Epoch 483/750 - Train Loss: 0.0254 - Val Loss: 3.2766\n",
            "Validation loss increased (3.2766), patience 285/1500\n",
            "Epoch 484/750 - Train Loss: 0.0256 - Val Loss: 3.1204\n",
            "Validation loss increased (3.1204), patience 286/1500\n",
            "Epoch 485/750 - Train Loss: 0.0266 - Val Loss: 4.1524\n",
            "Validation loss increased (4.1524), patience 287/1500\n",
            "Epoch 486/750 - Train Loss: 0.0257 - Val Loss: 3.7487\n",
            "Validation loss increased (3.7487), patience 288/1500\n",
            "Epoch 487/750 - Train Loss: 0.0251 - Val Loss: 3.0564\n",
            "Validation loss increased (3.0564), patience 289/1500\n",
            "Epoch 488/750 - Train Loss: 0.0249 - Val Loss: 4.1111\n",
            "Validation loss increased (4.1111), patience 290/1500\n",
            "Epoch 489/750 - Train Loss: 0.0252 - Val Loss: 4.2685\n",
            "Validation loss increased (4.2685), patience 291/1500\n",
            "Epoch 490/750 - Train Loss: 0.0331 - Val Loss: 4.8526\n",
            "Validation loss increased (4.8526), patience 292/1500\n",
            "Epoch 491/750 - Train Loss: 0.0325 - Val Loss: 4.6469\n",
            "Validation loss increased (4.6469), patience 293/1500\n",
            "Epoch 492/750 - Train Loss: 0.0307 - Val Loss: 3.8389\n",
            "Validation loss increased (3.8389), patience 294/1500\n",
            "Epoch 493/750 - Train Loss: 0.0301 - Val Loss: 5.1150\n",
            "Validation loss increased (5.1150), patience 295/1500\n",
            "Epoch 494/750 - Train Loss: 0.0304 - Val Loss: 4.3038\n",
            "Validation loss increased (4.3038), patience 296/1500\n",
            "Epoch 495/750 - Train Loss: 0.0294 - Val Loss: 3.5583\n",
            "Validation loss increased (3.5583), patience 297/1500\n",
            "Epoch 496/750 - Train Loss: 0.0291 - Val Loss: 4.0314\n",
            "Validation loss increased (4.0314), patience 298/1500\n",
            "Epoch 497/750 - Train Loss: 0.0305 - Val Loss: 3.7175\n",
            "Validation loss increased (3.7175), patience 299/1500\n",
            "Epoch 498/750 - Train Loss: 0.0298 - Val Loss: 3.7245\n",
            "Validation loss increased (3.7245), patience 300/1500\n",
            "Epoch 499/750 - Train Loss: 0.0292 - Val Loss: 4.4279\n",
            "Validation loss increased (4.4279), patience 301/1500\n",
            "Epoch 500/750 - Train Loss: 0.0296 - Val Loss: 3.7135\n",
            "Validation loss increased (3.7135), patience 302/1500\n",
            "Epoch 501/750 - Train Loss: 0.0288 - Val Loss: 3.4416\n",
            "Validation loss increased (3.4416), patience 303/1500\n",
            "Epoch 502/750 - Train Loss: 0.0288 - Val Loss: 4.4547\n",
            "Validation loss increased (4.4547), patience 304/1500\n",
            "Epoch 503/750 - Train Loss: 0.0286 - Val Loss: 4.3159\n",
            "Validation loss increased (4.3159), patience 305/1500\n",
            "Epoch 504/750 - Train Loss: 0.0284 - Val Loss: 2.7982\n",
            "Validation loss increased (2.7982), patience 306/1500\n",
            "Epoch 505/750 - Train Loss: 0.0293 - Val Loss: 4.1067\n",
            "Validation loss increased (4.1067), patience 307/1500\n",
            "Epoch 506/750 - Train Loss: 0.0283 - Val Loss: 3.3238\n",
            "Validation loss increased (3.3238), patience 308/1500\n",
            "Epoch 507/750 - Train Loss: 0.0283 - Val Loss: 3.4661\n",
            "Validation loss increased (3.4661), patience 309/1500\n",
            "Epoch 508/750 - Train Loss: 0.0296 - Val Loss: 3.9132\n",
            "Validation loss increased (3.9132), patience 310/1500\n",
            "Epoch 509/750 - Train Loss: 0.0284 - Val Loss: 4.0488\n",
            "Validation loss increased (4.0488), patience 311/1500\n",
            "Epoch 510/750 - Train Loss: 0.0281 - Val Loss: 3.2822\n",
            "Validation loss increased (3.2822), patience 312/1500\n",
            "Epoch 511/750 - Train Loss: 0.0279 - Val Loss: 3.4158\n",
            "Validation loss increased (3.4158), patience 313/1500\n",
            "Epoch 512/750 - Train Loss: 0.0277 - Val Loss: 4.1358\n",
            "Validation loss increased (4.1358), patience 314/1500\n",
            "Epoch 513/750 - Train Loss: 0.0281 - Val Loss: 3.4975\n",
            "Validation loss increased (3.4975), patience 315/1500\n",
            "Epoch 514/750 - Train Loss: 0.0279 - Val Loss: 3.5319\n",
            "Validation loss increased (3.5319), patience 316/1500\n",
            "Epoch 515/750 - Train Loss: 0.0310 - Val Loss: 4.0485\n",
            "Validation loss increased (4.0485), patience 317/1500\n",
            "Epoch 516/750 - Train Loss: 0.0287 - Val Loss: 4.4838\n",
            "Validation loss increased (4.4838), patience 318/1500\n",
            "Epoch 517/750 - Train Loss: 0.0286 - Val Loss: 4.3209\n",
            "Validation loss increased (4.3209), patience 319/1500\n",
            "Epoch 518/750 - Train Loss: 0.0285 - Val Loss: 3.5411\n",
            "Validation loss increased (3.5411), patience 320/1500\n",
            "Epoch 519/750 - Train Loss: 0.0283 - Val Loss: 3.8326\n",
            "Validation loss increased (3.8326), patience 321/1500\n",
            "Epoch 520/750 - Train Loss: 0.0281 - Val Loss: 4.3233\n",
            "Validation loss increased (4.3233), patience 322/1500\n",
            "Epoch 521/750 - Train Loss: 0.0277 - Val Loss: 2.9819\n",
            "Validation loss increased (2.9819), patience 323/1500\n",
            "Epoch 522/750 - Train Loss: 0.0286 - Val Loss: 3.5333\n",
            "Validation loss increased (3.5333), patience 324/1500\n",
            "Epoch 523/750 - Train Loss: 0.0278 - Val Loss: 4.8230\n",
            "Validation loss increased (4.8230), patience 325/1500\n",
            "Epoch 524/750 - Train Loss: 0.0276 - Val Loss: 3.0943\n",
            "Validation loss increased (3.0943), patience 326/1500\n",
            "Epoch 525/750 - Train Loss: 0.0279 - Val Loss: 5.5242\n",
            "Validation loss increased (5.5242), patience 327/1500\n",
            "Epoch 526/750 - Train Loss: 0.0280 - Val Loss: 3.7624\n",
            "Validation loss increased (3.7624), patience 328/1500\n",
            "Epoch 527/750 - Train Loss: 0.0272 - Val Loss: 3.4932\n",
            "Validation loss increased (3.4932), patience 329/1500\n",
            "Epoch 528/750 - Train Loss: 0.0275 - Val Loss: 4.4639\n",
            "Validation loss increased (4.4639), patience 330/1500\n",
            "Epoch 529/750 - Train Loss: 0.0272 - Val Loss: 3.7536\n",
            "Validation loss increased (3.7536), patience 331/1500\n",
            "Epoch 530/750 - Train Loss: 0.0272 - Val Loss: 3.1794\n",
            "Validation loss increased (3.1794), patience 332/1500\n",
            "Epoch 531/750 - Train Loss: 0.0276 - Val Loss: 3.7490\n",
            "Validation loss increased (3.7490), patience 333/1500\n",
            "Epoch 532/750 - Train Loss: 0.0273 - Val Loss: 3.9188\n",
            "Validation loss increased (3.9188), patience 334/1500\n",
            "Epoch 533/750 - Train Loss: 0.0270 - Val Loss: 2.9375\n",
            "Validation loss increased (2.9375), patience 335/1500\n",
            "Epoch 534/750 - Train Loss: 0.0273 - Val Loss: 4.5344\n",
            "Validation loss increased (4.5344), patience 336/1500\n",
            "Epoch 535/750 - Train Loss: 0.0273 - Val Loss: 3.3445\n",
            "Validation loss increased (3.3445), patience 337/1500\n",
            "Epoch 536/750 - Train Loss: 0.0273 - Val Loss: 3.6282\n",
            "Validation loss increased (3.6282), patience 338/1500\n",
            "Epoch 537/750 - Train Loss: 0.0267 - Val Loss: 3.6946\n",
            "Validation loss increased (3.6946), patience 339/1500\n",
            "Epoch 538/750 - Train Loss: 0.0269 - Val Loss: 3.7488\n",
            "Validation loss increased (3.7488), patience 340/1500\n",
            "Epoch 539/750 - Train Loss: 0.0263 - Val Loss: 4.8665\n",
            "Validation loss increased (4.8665), patience 341/1500\n",
            "Epoch 540/750 - Train Loss: 0.0266 - Val Loss: 4.0453\n",
            "Validation loss increased (4.0453), patience 342/1500\n",
            "Epoch 541/750 - Train Loss: 0.0281 - Val Loss: 2.4792\n",
            "Epoch 542/750 - Train Loss: 0.0284 - Val Loss: 4.5301\n",
            "Validation loss increased (4.5301), patience 1/1500\n",
            "Epoch 543/750 - Train Loss: 0.0284 - Val Loss: 3.7907\n",
            "Validation loss increased (3.7907), patience 2/1500\n",
            "Epoch 544/750 - Train Loss: 0.0279 - Val Loss: 3.2286\n",
            "Validation loss increased (3.2286), patience 3/1500\n",
            "Epoch 545/750 - Train Loss: 0.0273 - Val Loss: 2.9776\n",
            "Validation loss increased (2.9776), patience 4/1500\n",
            "Epoch 546/750 - Train Loss: 0.0267 - Val Loss: 4.4902\n",
            "Validation loss increased (4.4902), patience 5/1500\n",
            "Epoch 547/750 - Train Loss: 0.0268 - Val Loss: 4.2773\n",
            "Validation loss increased (4.2773), patience 6/1500\n",
            "Epoch 548/750 - Train Loss: 0.0270 - Val Loss: 3.8290\n",
            "Validation loss increased (3.8290), patience 7/1500\n",
            "Epoch 549/750 - Train Loss: 0.0269 - Val Loss: 3.0716\n",
            "Validation loss increased (3.0716), patience 8/1500\n",
            "Epoch 550/750 - Train Loss: 0.0270 - Val Loss: 4.4516\n",
            "Validation loss increased (4.4516), patience 9/1500\n",
            "Epoch 551/750 - Train Loss: 0.0262 - Val Loss: 2.9892\n",
            "Validation loss increased (2.9892), patience 10/1500\n",
            "Epoch 552/750 - Train Loss: 0.0270 - Val Loss: 3.1033\n",
            "Validation loss increased (3.1033), patience 11/1500\n",
            "Epoch 553/750 - Train Loss: 0.0262 - Val Loss: 3.4387\n",
            "Validation loss increased (3.4387), patience 12/1500\n",
            "Epoch 554/750 - Train Loss: 0.0285 - Val Loss: 2.9309\n",
            "Validation loss increased (2.9309), patience 13/1500\n",
            "Epoch 555/750 - Train Loss: 0.0273 - Val Loss: 3.1919\n",
            "Validation loss increased (3.1919), patience 14/1500\n",
            "Epoch 556/750 - Train Loss: 0.0263 - Val Loss: 3.5101\n",
            "Validation loss increased (3.5101), patience 15/1500\n",
            "Epoch 557/750 - Train Loss: 0.0264 - Val Loss: 3.3410\n",
            "Validation loss increased (3.3410), patience 16/1500\n",
            "Epoch 558/750 - Train Loss: 0.0267 - Val Loss: 4.6950\n",
            "Validation loss increased (4.6950), patience 17/1500\n",
            "Epoch 559/750 - Train Loss: 0.0259 - Val Loss: 2.5927\n",
            "Validation loss increased (2.5927), patience 18/1500\n",
            "Epoch 560/750 - Train Loss: 0.0263 - Val Loss: 3.2622\n",
            "Validation loss increased (3.2622), patience 19/1500\n",
            "Epoch 561/750 - Train Loss: 0.0260 - Val Loss: 2.6037\n",
            "Validation loss increased (2.6037), patience 20/1500\n",
            "Epoch 562/750 - Train Loss: 0.0260 - Val Loss: 4.6882\n",
            "Validation loss increased (4.6882), patience 21/1500\n",
            "Epoch 563/750 - Train Loss: 0.0262 - Val Loss: 3.4677\n",
            "Validation loss increased (3.4677), patience 22/1500\n",
            "Epoch 564/750 - Train Loss: 0.0263 - Val Loss: 3.5568\n",
            "Validation loss increased (3.5568), patience 23/1500\n",
            "Epoch 565/750 - Train Loss: 0.0263 - Val Loss: 2.9325\n",
            "Validation loss increased (2.9325), patience 24/1500\n",
            "Epoch 566/750 - Train Loss: 0.0257 - Val Loss: 3.5392\n",
            "Validation loss increased (3.5392), patience 25/1500\n",
            "Epoch 567/750 - Train Loss: 0.0254 - Val Loss: 3.7491\n",
            "Validation loss increased (3.7491), patience 26/1500\n",
            "Epoch 568/750 - Train Loss: 0.0259 - Val Loss: 2.9865\n",
            "Validation loss increased (2.9865), patience 27/1500\n",
            "Epoch 569/750 - Train Loss: 0.0280 - Val Loss: 4.7974\n",
            "Validation loss increased (4.7974), patience 28/1500\n",
            "Epoch 570/750 - Train Loss: 0.0263 - Val Loss: 3.9393\n",
            "Validation loss increased (3.9393), patience 29/1500\n",
            "Epoch 571/750 - Train Loss: 0.0260 - Val Loss: 3.2062\n",
            "Validation loss increased (3.2062), patience 30/1500\n",
            "Epoch 572/750 - Train Loss: 0.0256 - Val Loss: 2.7600\n",
            "Validation loss increased (2.7600), patience 31/1500\n",
            "Epoch 573/750 - Train Loss: 0.0257 - Val Loss: 3.2600\n",
            "Validation loss increased (3.2600), patience 32/1500\n",
            "Epoch 574/750 - Train Loss: 0.0263 - Val Loss: 4.3197\n",
            "Validation loss increased (4.3197), patience 33/1500\n",
            "Epoch 575/750 - Train Loss: 0.0255 - Val Loss: 3.4456\n",
            "Validation loss increased (3.4456), patience 34/1500\n",
            "Epoch 576/750 - Train Loss: 0.0250 - Val Loss: 3.2127\n",
            "Validation loss increased (3.2127), patience 35/1500\n",
            "Epoch 577/750 - Train Loss: 0.0254 - Val Loss: 3.5220\n",
            "Validation loss increased (3.5220), patience 36/1500\n",
            "Epoch 578/750 - Train Loss: 0.0251 - Val Loss: 3.5957\n",
            "Validation loss increased (3.5957), patience 37/1500\n",
            "Epoch 579/750 - Train Loss: 0.0251 - Val Loss: 3.4541\n",
            "Validation loss increased (3.4541), patience 38/1500\n",
            "Epoch 580/750 - Train Loss: 0.0292 - Val Loss: 3.4564\n",
            "Validation loss increased (3.4564), patience 39/1500\n",
            "Epoch 581/750 - Train Loss: 0.0259 - Val Loss: 3.4888\n",
            "Validation loss increased (3.4888), patience 40/1500\n",
            "Epoch 582/750 - Train Loss: 0.0252 - Val Loss: 3.7879\n",
            "Validation loss increased (3.7879), patience 41/1500\n",
            "Epoch 583/750 - Train Loss: 0.0261 - Val Loss: 2.7989\n",
            "Validation loss increased (2.7989), patience 42/1500\n",
            "Epoch 584/750 - Train Loss: 0.0279 - Val Loss: 3.9306\n",
            "Validation loss increased (3.9306), patience 43/1500\n",
            "Epoch 585/750 - Train Loss: 0.0277 - Val Loss: 4.2037\n",
            "Validation loss increased (4.2037), patience 44/1500\n",
            "Epoch 586/750 - Train Loss: 0.0279 - Val Loss: 6.3114\n",
            "Validation loss increased (6.3114), patience 45/1500\n",
            "Epoch 587/750 - Train Loss: 0.0301 - Val Loss: 3.6058\n",
            "Validation loss increased (3.6058), patience 46/1500\n",
            "Epoch 588/750 - Train Loss: 0.0284 - Val Loss: 4.6580\n",
            "Validation loss increased (4.6580), patience 47/1500\n",
            "Epoch 589/750 - Train Loss: 0.0278 - Val Loss: 3.6990\n",
            "Validation loss increased (3.6990), patience 48/1500\n",
            "Epoch 590/750 - Train Loss: 0.0274 - Val Loss: 3.7946\n",
            "Validation loss increased (3.7946), patience 49/1500\n",
            "Epoch 591/750 - Train Loss: 0.0285 - Val Loss: 4.5028\n",
            "Validation loss increased (4.5028), patience 50/1500\n",
            "Epoch 592/750 - Train Loss: 0.0284 - Val Loss: 4.2988\n",
            "Validation loss increased (4.2988), patience 51/1500\n",
            "Epoch 593/750 - Train Loss: 0.0289 - Val Loss: 3.7259\n",
            "Validation loss increased (3.7259), patience 52/1500\n",
            "Epoch 594/750 - Train Loss: 0.0276 - Val Loss: 3.6377\n",
            "Validation loss increased (3.6377), patience 53/1500\n",
            "Epoch 595/750 - Train Loss: 0.0270 - Val Loss: 3.5199\n",
            "Validation loss increased (3.5199), patience 54/1500\n",
            "Epoch 596/750 - Train Loss: 0.0262 - Val Loss: 3.1469\n",
            "Validation loss increased (3.1469), patience 55/1500\n",
            "Epoch 597/750 - Train Loss: 0.0257 - Val Loss: 3.5242\n",
            "Validation loss increased (3.5242), patience 56/1500\n",
            "Epoch 598/750 - Train Loss: 0.0267 - Val Loss: 2.9242\n",
            "Validation loss increased (2.9242), patience 57/1500\n",
            "Epoch 599/750 - Train Loss: 0.0270 - Val Loss: 5.3371\n",
            "Validation loss increased (5.3371), patience 58/1500\n",
            "Epoch 600/750 - Train Loss: 0.0263 - Val Loss: 3.8225\n",
            "Validation loss increased (3.8225), patience 59/1500\n",
            "Epoch 601/750 - Train Loss: 0.0256 - Val Loss: 3.8104\n",
            "Validation loss increased (3.8104), patience 60/1500\n",
            "Epoch 602/750 - Train Loss: 0.0266 - Val Loss: 3.4632\n",
            "Validation loss increased (3.4632), patience 61/1500\n",
            "Epoch 603/750 - Train Loss: 0.0253 - Val Loss: 2.9250\n",
            "Validation loss increased (2.9250), patience 62/1500\n",
            "Epoch 604/750 - Train Loss: 0.0255 - Val Loss: 3.2357\n",
            "Validation loss increased (3.2357), patience 63/1500\n",
            "Epoch 605/750 - Train Loss: 0.0252 - Val Loss: 3.2683\n",
            "Validation loss increased (3.2683), patience 64/1500\n",
            "Epoch 606/750 - Train Loss: 0.0250 - Val Loss: 3.3409\n",
            "Validation loss increased (3.3409), patience 65/1500\n",
            "Epoch 607/750 - Train Loss: 0.0258 - Val Loss: 4.7082\n",
            "Validation loss increased (4.7082), patience 66/1500\n",
            "Epoch 608/750 - Train Loss: 0.0250 - Val Loss: 4.4488\n",
            "Validation loss increased (4.4488), patience 67/1500\n",
            "Epoch 609/750 - Train Loss: 0.0254 - Val Loss: 3.1533\n",
            "Validation loss increased (3.1533), patience 68/1500\n",
            "Epoch 610/750 - Train Loss: 0.0259 - Val Loss: 3.3467\n",
            "Validation loss increased (3.3467), patience 69/1500\n",
            "Epoch 611/750 - Train Loss: 0.0265 - Val Loss: 3.8368\n",
            "Validation loss increased (3.8368), patience 70/1500\n",
            "Epoch 612/750 - Train Loss: 0.0252 - Val Loss: 2.8058\n",
            "Validation loss increased (2.8058), patience 71/1500\n",
            "Epoch 613/750 - Train Loss: 0.0252 - Val Loss: 3.5584\n",
            "Validation loss increased (3.5584), patience 72/1500\n",
            "Epoch 614/750 - Train Loss: 0.0260 - Val Loss: 4.1334\n",
            "Validation loss increased (4.1334), patience 73/1500\n",
            "Epoch 615/750 - Train Loss: 0.0250 - Val Loss: 4.0942\n",
            "Validation loss increased (4.0942), patience 74/1500\n",
            "Epoch 616/750 - Train Loss: 0.0253 - Val Loss: 3.5203\n",
            "Validation loss increased (3.5203), patience 75/1500\n",
            "Epoch 617/750 - Train Loss: 0.0246 - Val Loss: 3.7774\n",
            "Validation loss increased (3.7774), patience 76/1500\n",
            "Epoch 618/750 - Train Loss: 0.0263 - Val Loss: 3.0098\n",
            "Validation loss increased (3.0098), patience 77/1500\n",
            "Epoch 619/750 - Train Loss: 0.0259 - Val Loss: 3.9898\n",
            "Validation loss increased (3.9898), patience 78/1500\n",
            "Epoch 620/750 - Train Loss: 0.0252 - Val Loss: 3.0581\n",
            "Validation loss increased (3.0581), patience 79/1500\n",
            "Epoch 621/750 - Train Loss: 0.0262 - Val Loss: 3.3017\n",
            "Validation loss increased (3.3017), patience 80/1500\n",
            "Epoch 622/750 - Train Loss: 0.0257 - Val Loss: 4.0897\n",
            "Validation loss increased (4.0897), patience 81/1500\n",
            "Epoch 623/750 - Train Loss: 0.0269 - Val Loss: 3.9265\n",
            "Validation loss increased (3.9265), patience 82/1500\n",
            "Epoch 624/750 - Train Loss: 0.0253 - Val Loss: 3.9210\n",
            "Validation loss increased (3.9210), patience 83/1500\n",
            "Epoch 625/750 - Train Loss: 0.0249 - Val Loss: 3.7988\n",
            "Validation loss increased (3.7988), patience 84/1500\n",
            "Epoch 626/750 - Train Loss: 0.0248 - Val Loss: 3.2284\n",
            "Validation loss increased (3.2284), patience 85/1500\n",
            "Epoch 627/750 - Train Loss: 0.0249 - Val Loss: 3.1709\n",
            "Validation loss increased (3.1709), patience 86/1500\n",
            "Epoch 628/750 - Train Loss: 0.0254 - Val Loss: 3.4278\n",
            "Validation loss increased (3.4278), patience 87/1500\n",
            "Epoch 629/750 - Train Loss: 0.0268 - Val Loss: 4.5841\n",
            "Validation loss increased (4.5841), patience 88/1500\n",
            "Epoch 630/750 - Train Loss: 0.0271 - Val Loss: 5.7793\n",
            "Validation loss increased (5.7793), patience 89/1500\n",
            "Epoch 631/750 - Train Loss: 0.0277 - Val Loss: 3.4683\n",
            "Validation loss increased (3.4683), patience 90/1500\n",
            "Epoch 632/750 - Train Loss: 0.0293 - Val Loss: 3.5080\n",
            "Validation loss increased (3.5080), patience 91/1500\n",
            "Epoch 633/750 - Train Loss: 0.0291 - Val Loss: 3.9194\n",
            "Validation loss increased (3.9194), patience 92/1500\n",
            "Epoch 634/750 - Train Loss: 0.0286 - Val Loss: 4.0028\n",
            "Validation loss increased (4.0028), patience 93/1500\n",
            "Epoch 635/750 - Train Loss: 0.0274 - Val Loss: 4.2013\n",
            "Validation loss increased (4.2013), patience 94/1500\n",
            "Epoch 636/750 - Train Loss: 0.0271 - Val Loss: 3.9711\n",
            "Validation loss increased (3.9711), patience 95/1500\n",
            "Epoch 637/750 - Train Loss: 0.0269 - Val Loss: 3.2216\n",
            "Validation loss increased (3.2216), patience 96/1500\n",
            "Epoch 638/750 - Train Loss: 0.0273 - Val Loss: 4.0292\n",
            "Validation loss increased (4.0292), patience 97/1500\n",
            "Epoch 639/750 - Train Loss: 0.0267 - Val Loss: 3.4536\n",
            "Validation loss increased (3.4536), patience 98/1500\n",
            "Epoch 640/750 - Train Loss: 0.0280 - Val Loss: 4.1627\n",
            "Validation loss increased (4.1627), patience 99/1500\n",
            "Epoch 641/750 - Train Loss: 0.0275 - Val Loss: 3.4433\n",
            "Validation loss increased (3.4433), patience 100/1500\n",
            "Epoch 642/750 - Train Loss: 0.0266 - Val Loss: 3.7298\n",
            "Validation loss increased (3.7298), patience 101/1500\n",
            "Epoch 643/750 - Train Loss: 0.0264 - Val Loss: 4.1337\n",
            "Validation loss increased (4.1337), patience 102/1500\n",
            "Epoch 644/750 - Train Loss: 0.0259 - Val Loss: 3.4829\n",
            "Validation loss increased (3.4829), patience 103/1500\n",
            "Epoch 645/750 - Train Loss: 0.0260 - Val Loss: 3.3142\n",
            "Validation loss increased (3.3142), patience 104/1500\n",
            "Epoch 646/750 - Train Loss: 0.0267 - Val Loss: 3.4813\n",
            "Validation loss increased (3.4813), patience 105/1500\n",
            "Epoch 647/750 - Train Loss: 0.0261 - Val Loss: 3.7084\n",
            "Validation loss increased (3.7084), patience 106/1500\n",
            "Epoch 648/750 - Train Loss: 0.0262 - Val Loss: 3.7784\n",
            "Validation loss increased (3.7784), patience 107/1500\n",
            "Epoch 649/750 - Train Loss: 0.0266 - Val Loss: 4.2808\n",
            "Validation loss increased (4.2808), patience 108/1500\n",
            "Epoch 650/750 - Train Loss: 0.0265 - Val Loss: 3.4238\n",
            "Validation loss increased (3.4238), patience 109/1500\n",
            "Epoch 651/750 - Train Loss: 0.0261 - Val Loss: 2.8303\n",
            "Validation loss increased (2.8303), patience 110/1500\n",
            "Epoch 652/750 - Train Loss: 0.0264 - Val Loss: 4.0982\n",
            "Validation loss increased (4.0982), patience 111/1500\n",
            "Epoch 653/750 - Train Loss: 0.0263 - Val Loss: 3.2939\n",
            "Validation loss increased (3.2939), patience 112/1500\n",
            "Epoch 654/750 - Train Loss: 0.0256 - Val Loss: 3.3495\n",
            "Validation loss increased (3.3495), patience 113/1500\n",
            "Epoch 655/750 - Train Loss: 0.0257 - Val Loss: 3.5915\n",
            "Validation loss increased (3.5915), patience 114/1500\n",
            "Epoch 656/750 - Train Loss: 0.0256 - Val Loss: 3.4452\n",
            "Validation loss increased (3.4452), patience 115/1500\n",
            "Epoch 657/750 - Train Loss: 0.0260 - Val Loss: 3.5045\n",
            "Validation loss increased (3.5045), patience 116/1500\n",
            "Epoch 658/750 - Train Loss: 0.0259 - Val Loss: 3.7179\n",
            "Validation loss increased (3.7179), patience 117/1500\n",
            "Epoch 659/750 - Train Loss: 0.0257 - Val Loss: 3.4070\n",
            "Validation loss increased (3.4070), patience 118/1500\n",
            "Epoch 660/750 - Train Loss: 0.0253 - Val Loss: 3.2821\n",
            "Validation loss increased (3.2821), patience 119/1500\n",
            "Epoch 661/750 - Train Loss: 0.0251 - Val Loss: 3.8321\n",
            "Validation loss increased (3.8321), patience 120/1500\n",
            "Epoch 662/750 - Train Loss: 0.0261 - Val Loss: 4.3211\n",
            "Validation loss increased (4.3211), patience 121/1500\n",
            "Epoch 663/750 - Train Loss: 0.0260 - Val Loss: 3.1488\n",
            "Validation loss increased (3.1488), patience 122/1500\n",
            "Epoch 664/750 - Train Loss: 0.0259 - Val Loss: 4.1761\n",
            "Validation loss increased (4.1761), patience 123/1500\n",
            "Epoch 665/750 - Train Loss: 0.0250 - Val Loss: 3.1891\n",
            "Validation loss increased (3.1891), patience 124/1500\n",
            "Epoch 666/750 - Train Loss: 0.0249 - Val Loss: 3.5165\n",
            "Validation loss increased (3.5165), patience 125/1500\n",
            "Epoch 667/750 - Train Loss: 0.0249 - Val Loss: 3.4780\n",
            "Validation loss increased (3.4780), patience 126/1500\n",
            "Epoch 668/750 - Train Loss: 0.0253 - Val Loss: 4.1494\n",
            "Validation loss increased (4.1494), patience 127/1500\n",
            "Epoch 669/750 - Train Loss: 0.0255 - Val Loss: 3.9522\n",
            "Validation loss increased (3.9522), patience 128/1500\n",
            "Epoch 670/750 - Train Loss: 0.0250 - Val Loss: 3.2566\n",
            "Validation loss increased (3.2566), patience 129/1500\n",
            "Epoch 671/750 - Train Loss: 0.0257 - Val Loss: 3.3416\n",
            "Validation loss increased (3.3416), patience 130/1500\n",
            "Epoch 672/750 - Train Loss: 0.0247 - Val Loss: 3.2403\n",
            "Validation loss increased (3.2403), patience 131/1500\n",
            "Epoch 673/750 - Train Loss: 0.0247 - Val Loss: 4.0349\n",
            "Validation loss increased (4.0349), patience 132/1500\n",
            "Epoch 674/750 - Train Loss: 0.0262 - Val Loss: 4.1884\n",
            "Validation loss increased (4.1884), patience 133/1500\n",
            "Epoch 675/750 - Train Loss: 0.0253 - Val Loss: 3.6270\n",
            "Validation loss increased (3.6270), patience 134/1500\n",
            "Epoch 676/750 - Train Loss: 0.0250 - Val Loss: 4.6576\n",
            "Validation loss increased (4.6576), patience 135/1500\n",
            "Epoch 677/750 - Train Loss: 0.0255 - Val Loss: 3.4137\n",
            "Validation loss increased (3.4137), patience 136/1500\n",
            "Epoch 678/750 - Train Loss: 0.0251 - Val Loss: 3.3931\n",
            "Validation loss increased (3.3931), patience 137/1500\n",
            "Epoch 679/750 - Train Loss: 0.0274 - Val Loss: 4.7634\n",
            "Validation loss increased (4.7634), patience 138/1500\n",
            "Epoch 680/750 - Train Loss: 0.0272 - Val Loss: 4.0630\n",
            "Validation loss increased (4.0630), patience 139/1500\n",
            "Epoch 681/750 - Train Loss: 0.0258 - Val Loss: 3.3229\n",
            "Validation loss increased (3.3229), patience 140/1500\n",
            "Epoch 682/750 - Train Loss: 0.0253 - Val Loss: 3.3811\n",
            "Validation loss increased (3.3811), patience 141/1500\n",
            "Epoch 683/750 - Train Loss: 0.0263 - Val Loss: 3.6889\n",
            "Validation loss increased (3.6889), patience 142/1500\n",
            "Epoch 684/750 - Train Loss: 0.0278 - Val Loss: 3.6120\n",
            "Validation loss increased (3.6120), patience 143/1500\n",
            "Epoch 685/750 - Train Loss: 0.0259 - Val Loss: 3.4846\n",
            "Validation loss increased (3.4846), patience 144/1500\n",
            "Epoch 686/750 - Train Loss: 0.0248 - Val Loss: 3.5290\n",
            "Validation loss increased (3.5290), patience 145/1500\n",
            "Epoch 687/750 - Train Loss: 0.0247 - Val Loss: 3.8544\n",
            "Validation loss increased (3.8544), patience 146/1500\n",
            "Epoch 688/750 - Train Loss: 0.0244 - Val Loss: 3.3655\n",
            "Validation loss increased (3.3655), patience 147/1500\n",
            "Epoch 689/750 - Train Loss: 0.0258 - Val Loss: 3.9687\n",
            "Validation loss increased (3.9687), patience 148/1500\n",
            "Epoch 690/750 - Train Loss: 0.0253 - Val Loss: 3.0083\n",
            "Validation loss increased (3.0083), patience 149/1500\n",
            "Epoch 691/750 - Train Loss: 0.0250 - Val Loss: 3.7371\n",
            "Validation loss increased (3.7371), patience 150/1500\n",
            "Epoch 692/750 - Train Loss: 0.0242 - Val Loss: 3.1830\n",
            "Validation loss increased (3.1830), patience 151/1500\n",
            "Epoch 693/750 - Train Loss: 0.0242 - Val Loss: 3.0921\n",
            "Validation loss increased (3.0921), patience 152/1500\n",
            "Epoch 694/750 - Train Loss: 0.0253 - Val Loss: 3.1569\n",
            "Validation loss increased (3.1569), patience 153/1500\n",
            "Epoch 695/750 - Train Loss: 0.0244 - Val Loss: 3.4210\n",
            "Validation loss increased (3.4210), patience 154/1500\n",
            "Epoch 696/750 - Train Loss: 0.0253 - Val Loss: 4.0433\n",
            "Validation loss increased (4.0433), patience 155/1500\n",
            "Epoch 697/750 - Train Loss: 0.0286 - Val Loss: 3.7034\n",
            "Validation loss increased (3.7034), patience 156/1500\n",
            "Epoch 698/750 - Train Loss: 0.0284 - Val Loss: 3.9715\n",
            "Validation loss increased (3.9715), patience 157/1500\n",
            "Epoch 699/750 - Train Loss: 0.0265 - Val Loss: 3.6044\n",
            "Validation loss increased (3.6044), patience 158/1500\n",
            "Epoch 700/750 - Train Loss: 0.0261 - Val Loss: 4.6158\n",
            "Validation loss increased (4.6158), patience 159/1500\n",
            "Epoch 701/750 - Train Loss: 0.0251 - Val Loss: 4.0000\n",
            "Validation loss increased (4.0000), patience 160/1500\n",
            "Epoch 702/750 - Train Loss: 0.0257 - Val Loss: 3.8443\n",
            "Validation loss increased (3.8443), patience 161/1500\n",
            "Epoch 703/750 - Train Loss: 0.0251 - Val Loss: 3.2829\n",
            "Validation loss increased (3.2829), patience 162/1500\n",
            "Epoch 704/750 - Train Loss: 0.0258 - Val Loss: 3.1965\n",
            "Validation loss increased (3.1965), patience 163/1500\n",
            "Epoch 705/750 - Train Loss: 0.0253 - Val Loss: 3.1814\n",
            "Validation loss increased (3.1814), patience 164/1500\n",
            "Epoch 706/750 - Train Loss: 0.0248 - Val Loss: 3.0342\n",
            "Validation loss increased (3.0342), patience 165/1500\n",
            "Epoch 707/750 - Train Loss: 0.0253 - Val Loss: 3.1113\n",
            "Validation loss increased (3.1113), patience 166/1500\n",
            "Epoch 708/750 - Train Loss: 0.0265 - Val Loss: 3.9173\n",
            "Validation loss increased (3.9173), patience 167/1500\n",
            "Epoch 709/750 - Train Loss: 0.0258 - Val Loss: 4.6057\n",
            "Validation loss increased (4.6057), patience 168/1500\n",
            "Epoch 710/750 - Train Loss: 0.0255 - Val Loss: 3.2560\n",
            "Validation loss increased (3.2560), patience 169/1500\n",
            "Epoch 711/750 - Train Loss: 0.0259 - Val Loss: 4.5307\n",
            "Validation loss increased (4.5307), patience 170/1500\n",
            "Epoch 712/750 - Train Loss: 0.0270 - Val Loss: 3.0837\n",
            "Validation loss increased (3.0837), patience 171/1500\n",
            "Epoch 713/750 - Train Loss: 0.0264 - Val Loss: 3.5444\n",
            "Validation loss increased (3.5444), patience 172/1500\n",
            "Epoch 714/750 - Train Loss: 0.0259 - Val Loss: 3.0752\n",
            "Validation loss increased (3.0752), patience 173/1500\n",
            "Epoch 715/750 - Train Loss: 0.0254 - Val Loss: 3.2795\n",
            "Validation loss increased (3.2795), patience 174/1500\n",
            "Epoch 716/750 - Train Loss: 0.0251 - Val Loss: 4.4648\n",
            "Validation loss increased (4.4648), patience 175/1500\n",
            "Epoch 717/750 - Train Loss: 0.0254 - Val Loss: 3.6396\n",
            "Validation loss increased (3.6396), patience 176/1500\n",
            "Epoch 718/750 - Train Loss: 0.0254 - Val Loss: 3.1145\n",
            "Validation loss increased (3.1145), patience 177/1500\n",
            "Epoch 719/750 - Train Loss: 0.0250 - Val Loss: 3.4764\n",
            "Validation loss increased (3.4764), patience 178/1500\n",
            "Epoch 720/750 - Train Loss: 0.0280 - Val Loss: 3.6266\n",
            "Validation loss increased (3.6266), patience 179/1500\n",
            "Epoch 721/750 - Train Loss: 0.0279 - Val Loss: 4.3408\n",
            "Validation loss increased (4.3408), patience 180/1500\n",
            "Epoch 722/750 - Train Loss: 0.0265 - Val Loss: 4.0494\n",
            "Validation loss increased (4.0494), patience 181/1500\n",
            "Epoch 723/750 - Train Loss: 0.0258 - Val Loss: 4.1551\n",
            "Validation loss increased (4.1551), patience 182/1500\n",
            "Epoch 724/750 - Train Loss: 0.0265 - Val Loss: 3.1746\n",
            "Validation loss increased (3.1746), patience 183/1500\n",
            "Epoch 725/750 - Train Loss: 0.0267 - Val Loss: 3.5769\n",
            "Validation loss increased (3.5769), patience 184/1500\n",
            "Epoch 726/750 - Train Loss: 0.0253 - Val Loss: 3.2226\n",
            "Validation loss increased (3.2226), patience 185/1500\n",
            "Epoch 727/750 - Train Loss: 0.0252 - Val Loss: 2.8032\n",
            "Validation loss increased (2.8032), patience 186/1500\n",
            "Epoch 728/750 - Train Loss: 0.0253 - Val Loss: 3.7707\n",
            "Validation loss increased (3.7707), patience 187/1500\n",
            "Epoch 729/750 - Train Loss: 0.0255 - Val Loss: 3.9457\n",
            "Validation loss increased (3.9457), patience 188/1500\n",
            "Epoch 730/750 - Train Loss: 0.0255 - Val Loss: 3.6121\n",
            "Validation loss increased (3.6121), patience 189/1500\n",
            "Epoch 731/750 - Train Loss: 0.0258 - Val Loss: 3.2213\n",
            "Validation loss increased (3.2213), patience 190/1500\n",
            "Epoch 732/750 - Train Loss: 0.0257 - Val Loss: 4.0486\n",
            "Validation loss increased (4.0486), patience 191/1500\n",
            "Epoch 733/750 - Train Loss: 0.0251 - Val Loss: 5.2041\n",
            "Validation loss increased (5.2041), patience 192/1500\n",
            "Epoch 734/750 - Train Loss: 0.0247 - Val Loss: 4.1401\n",
            "Validation loss increased (4.1401), patience 193/1500\n",
            "Epoch 735/750 - Train Loss: 0.0253 - Val Loss: 3.5958\n",
            "Validation loss increased (3.5958), patience 194/1500\n",
            "Epoch 736/750 - Train Loss: 0.0252 - Val Loss: 3.3833\n",
            "Validation loss increased (3.3833), patience 195/1500\n",
            "Epoch 737/750 - Train Loss: 0.0253 - Val Loss: 3.4408\n",
            "Validation loss increased (3.4408), patience 196/1500\n",
            "Epoch 738/750 - Train Loss: 0.0256 - Val Loss: 3.1830\n",
            "Validation loss increased (3.1830), patience 197/1500\n",
            "Epoch 739/750 - Train Loss: 0.0253 - Val Loss: 3.5505\n",
            "Validation loss increased (3.5505), patience 198/1500\n",
            "Epoch 740/750 - Train Loss: 0.0258 - Val Loss: 3.6962\n",
            "Validation loss increased (3.6962), patience 199/1500\n",
            "Epoch 741/750 - Train Loss: 0.0256 - Val Loss: 3.3823\n",
            "Validation loss increased (3.3823), patience 200/1500\n",
            "Epoch 742/750 - Train Loss: 0.0245 - Val Loss: 3.7515\n",
            "Validation loss increased (3.7515), patience 201/1500\n",
            "Epoch 743/750 - Train Loss: 0.0251 - Val Loss: 3.1530\n",
            "Validation loss increased (3.1530), patience 202/1500\n",
            "Epoch 744/750 - Train Loss: 0.0248 - Val Loss: 3.4995\n",
            "Validation loss increased (3.4995), patience 203/1500\n",
            "Epoch 745/750 - Train Loss: 0.0248 - Val Loss: 3.1124\n",
            "Validation loss increased (3.1124), patience 204/1500\n",
            "Epoch 746/750 - Train Loss: 0.0250 - Val Loss: 3.2188\n",
            "Validation loss increased (3.2188), patience 205/1500\n",
            "Epoch 747/750 - Train Loss: 0.0247 - Val Loss: 3.3453\n",
            "Validation loss increased (3.3453), patience 206/1500\n",
            "Epoch 748/750 - Train Loss: 0.0246 - Val Loss: 3.1243\n",
            "Validation loss increased (3.1243), patience 207/1500\n",
            "Epoch 749/750 - Train Loss: 0.0244 - Val Loss: 3.9928\n",
            "Validation loss increased (3.9928), patience 208/1500\n",
            "Epoch 750/750 - Train Loss: 0.0260 - Val Loss: 3.1062\n",
            "Validation loss increased (3.1062), patience 209/1500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use classification to guage model performance, using confusion matrix for performance evauation on test set\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluate model on test set\n",
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for X_batch, _ in test_loader:\n",
        "        X_batch = X_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        all_preds.extend(outputs.cpu().numpy())\n",
        "\n",
        "y_pred = np.array(all_preds)\n",
        "y_true = y_test.cpu().numpy()\n",
        "# Convert predictions and targets from log-scale to linear scale\n",
        "y_pred_linear = 10 ** y_pred\n",
        "y_true_linear = 10 ** y_true\n",
        "\n",
        "# Define intensity bins for flare classes\n",
        "bins = [0, 1e-7, 1e-6, 1e-5, 1e-4, np.inf]\n",
        "labels = ['N', 'B', 'C', 'M', 'X']\n",
        "class_indices = list(range(len(labels)))  # [0, 1, 2, 3, 4]\n",
        "\n",
        "# Bin true and predicted values into classes\n",
        "y_true_class = np.digitize(y_true_linear, bins) - 1\n",
        "y_pred_class = np.digitize(y_pred_linear, bins) - 1\n",
        "\n",
        "# Plot confusion matrix\n",
        "unique_labels = sorted(np.unique(np.concatenate([y_true_class, y_pred_class])))\n",
        "display_labels = [labels[i] for i in unique_labels]\n",
        "\n",
        "cm = confusion_matrix(y_true_class, y_pred_class, labels=class_indices)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=display_labels)\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix (Flare Classes from Regression Output)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "565LdomhMMJy",
        "outputId": "5fed14bf-0dcd-4a20-9d21-2316f26daa9c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VWLS3rKGMMvy"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}